{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E01: train a trigram language model, i.e. take two characters as an input to predict the 3rd one. Feel free to use either counting or a neural net. Evaluate the loss; Did it improve over a bigram model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = open('names.txt', 'r').read().splitlines()\n",
    "xs = []\n",
    "ys = []\n",
    "\n",
    "for w in words:\n",
    "    chrs = [\".\"] + [\".\"] + list(w) + [\".\"] \n",
    "    for i in range(len(chrs) - 2):\n",
    "        first_2_char = chrs[i] + chrs[i + 1]\n",
    "        second_char = chrs[i + 2]\n",
    "        xs.append(first_2_char)\n",
    "        ys.append(second_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_list = set(xs)\n",
    "char_list_single = set(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi_data = {s:i for i,s in enumerate(char_list)}\n",
    "itos_data = {i:s for i,s in enumerate(char_list)}\n",
    "\n",
    "stoi_labels = {s:i for i,s in enumerate(char_list_single)}\n",
    "itos_labels = {i:s for i,s in enumerate(char_list_single)}\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for w in words:\n",
    "    chrs = [\".\"] + [\".\"] + list(w) + [\".\"] \n",
    "    for i in range(len(chrs) - 2):\n",
    "        first_2_char = chrs[i] + chrs[i + 1]\n",
    "        second_char = chrs[i + 2]\n",
    "\n",
    "        data.append(stoi_data[first_2_char])\n",
    "        labels.append(stoi_labels[second_char])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch\n",
    "encoding_size = len(stoi_data.keys())\n",
    "\n",
    "encoded = F.one_hot(torch.tensor(data), encoding_size).float()\n",
    "W = torch.randn((encoding_size, 27), requires_grad=True).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.5079, grad_fn=<NegBackward0>)\n",
      "tensor(2.5057, grad_fn=<NegBackward0>)\n",
      "tensor(2.5035, grad_fn=<NegBackward0>)\n",
      "tensor(2.5014, grad_fn=<NegBackward0>)\n",
      "tensor(2.4993, grad_fn=<NegBackward0>)\n",
      "tensor(2.4972, grad_fn=<NegBackward0>)\n",
      "tensor(2.4952, grad_fn=<NegBackward0>)\n",
      "tensor(2.4932, grad_fn=<NegBackward0>)\n",
      "tensor(2.4912, grad_fn=<NegBackward0>)\n",
      "tensor(2.4893, grad_fn=<NegBackward0>)\n",
      "tensor(2.4873, grad_fn=<NegBackward0>)\n",
      "tensor(2.4854, grad_fn=<NegBackward0>)\n",
      "tensor(2.4836, grad_fn=<NegBackward0>)\n",
      "tensor(2.4817, grad_fn=<NegBackward0>)\n",
      "tensor(2.4799, grad_fn=<NegBackward0>)\n",
      "tensor(2.4781, grad_fn=<NegBackward0>)\n",
      "tensor(2.4763, grad_fn=<NegBackward0>)\n",
      "tensor(2.4746, grad_fn=<NegBackward0>)\n",
      "tensor(2.4728, grad_fn=<NegBackward0>)\n",
      "tensor(2.4711, grad_fn=<NegBackward0>)\n",
      "tensor(2.4695, grad_fn=<NegBackward0>)\n",
      "tensor(2.4678, grad_fn=<NegBackward0>)\n",
      "tensor(2.4662, grad_fn=<NegBackward0>)\n",
      "tensor(2.4645, grad_fn=<NegBackward0>)\n",
      "tensor(2.4629, grad_fn=<NegBackward0>)\n",
      "tensor(2.4614, grad_fn=<NegBackward0>)\n",
      "tensor(2.4598, grad_fn=<NegBackward0>)\n",
      "tensor(2.4582, grad_fn=<NegBackward0>)\n",
      "tensor(2.4567, grad_fn=<NegBackward0>)\n",
      "tensor(2.4552, grad_fn=<NegBackward0>)\n",
      "tensor(2.4537, grad_fn=<NegBackward0>)\n",
      "tensor(2.4523, grad_fn=<NegBackward0>)\n",
      "tensor(2.4508, grad_fn=<NegBackward0>)\n",
      "tensor(2.4494, grad_fn=<NegBackward0>)\n",
      "tensor(2.4480, grad_fn=<NegBackward0>)\n",
      "tensor(2.4465, grad_fn=<NegBackward0>)\n",
      "tensor(2.4452, grad_fn=<NegBackward0>)\n",
      "tensor(2.4438, grad_fn=<NegBackward0>)\n",
      "tensor(2.4424, grad_fn=<NegBackward0>)\n",
      "tensor(2.4411, grad_fn=<NegBackward0>)\n",
      "tensor(2.4398, grad_fn=<NegBackward0>)\n",
      "tensor(2.4385, grad_fn=<NegBackward0>)\n",
      "tensor(2.4372, grad_fn=<NegBackward0>)\n",
      "tensor(2.4359, grad_fn=<NegBackward0>)\n",
      "tensor(2.4346, grad_fn=<NegBackward0>)\n",
      "tensor(2.4334, grad_fn=<NegBackward0>)\n",
      "tensor(2.4321, grad_fn=<NegBackward0>)\n",
      "tensor(2.4309, grad_fn=<NegBackward0>)\n",
      "tensor(2.4297, grad_fn=<NegBackward0>)\n",
      "tensor(2.4285, grad_fn=<NegBackward0>)\n",
      "tensor(2.4273, grad_fn=<NegBackward0>)\n",
      "tensor(2.4261, grad_fn=<NegBackward0>)\n",
      "tensor(2.4249, grad_fn=<NegBackward0>)\n",
      "tensor(2.4238, grad_fn=<NegBackward0>)\n",
      "tensor(2.4226, grad_fn=<NegBackward0>)\n",
      "tensor(2.4215, grad_fn=<NegBackward0>)\n",
      "tensor(2.4204, grad_fn=<NegBackward0>)\n",
      "tensor(2.4193, grad_fn=<NegBackward0>)\n",
      "tensor(2.4182, grad_fn=<NegBackward0>)\n",
      "tensor(2.4171, grad_fn=<NegBackward0>)\n",
      "tensor(2.4160, grad_fn=<NegBackward0>)\n",
      "tensor(2.4150, grad_fn=<NegBackward0>)\n",
      "tensor(2.4139, grad_fn=<NegBackward0>)\n",
      "tensor(2.4129, grad_fn=<NegBackward0>)\n",
      "tensor(2.4118, grad_fn=<NegBackward0>)\n",
      "tensor(2.4108, grad_fn=<NegBackward0>)\n",
      "tensor(2.4098, grad_fn=<NegBackward0>)\n",
      "tensor(2.4088, grad_fn=<NegBackward0>)\n",
      "tensor(2.4078, grad_fn=<NegBackward0>)\n",
      "tensor(2.4068, grad_fn=<NegBackward0>)\n",
      "tensor(2.4058, grad_fn=<NegBackward0>)\n",
      "tensor(2.4049, grad_fn=<NegBackward0>)\n",
      "tensor(2.4039, grad_fn=<NegBackward0>)\n",
      "tensor(2.4029, grad_fn=<NegBackward0>)\n",
      "tensor(2.4020, grad_fn=<NegBackward0>)\n",
      "tensor(2.4011, grad_fn=<NegBackward0>)\n",
      "tensor(2.4001, grad_fn=<NegBackward0>)\n",
      "tensor(2.3992, grad_fn=<NegBackward0>)\n",
      "tensor(2.3983, grad_fn=<NegBackward0>)\n",
      "tensor(2.3974, grad_fn=<NegBackward0>)\n",
      "tensor(2.3965, grad_fn=<NegBackward0>)\n",
      "tensor(2.3956, grad_fn=<NegBackward0>)\n",
      "tensor(2.3948, grad_fn=<NegBackward0>)\n",
      "tensor(2.3939, grad_fn=<NegBackward0>)\n",
      "tensor(2.3930, grad_fn=<NegBackward0>)\n",
      "tensor(2.3922, grad_fn=<NegBackward0>)\n",
      "tensor(2.3913, grad_fn=<NegBackward0>)\n",
      "tensor(2.3905, grad_fn=<NegBackward0>)\n",
      "tensor(2.3896, grad_fn=<NegBackward0>)\n",
      "tensor(2.3888, grad_fn=<NegBackward0>)\n",
      "tensor(2.3880, grad_fn=<NegBackward0>)\n",
      "tensor(2.3872, grad_fn=<NegBackward0>)\n",
      "tensor(2.3864, grad_fn=<NegBackward0>)\n",
      "tensor(2.3856, grad_fn=<NegBackward0>)\n",
      "tensor(2.3848, grad_fn=<NegBackward0>)\n",
      "tensor(2.3840, grad_fn=<NegBackward0>)\n",
      "tensor(2.3832, grad_fn=<NegBackward0>)\n",
      "tensor(2.3824, grad_fn=<NegBackward0>)\n",
      "tensor(2.3817, grad_fn=<NegBackward0>)\n",
      "tensor(2.3809, grad_fn=<NegBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    logits = (encoded @ W)\n",
    "    counts = logits.exp()\n",
    "    probs = counts / counts.sum(1, keepdim=True)\n",
    "\n",
    "    loss = -probs[torch.arange(len(labels)), labels].log().mean()\n",
    "\n",
    "    W.grad = None\n",
    "    loss.backward()\n",
    "    W.data += -W.grad * 50\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dowtxcto.\n",
      "de.\n",
      "fte.\n",
      "ni.\n",
      "rebideann.\n",
      "elio.\n",
      "raysbuhnivdctwzlstchanit.\n",
      "ton.\n",
      "jevbhqerynnan.\n",
      "stino.\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    word = []\n",
    "    chars = \"..\"\n",
    "\n",
    "    while True:\n",
    "        current = chars[-2:]\n",
    "        datas = stoi_data.get(current, stoi_data[\"..\"])\n",
    "        encoded_v = F.one_hot(torch.tensor(datas), encoding_size).float()\n",
    "\n",
    "        logits = encoded_v @ W\n",
    "        nums = logits.exp()\n",
    "        prob = nums / nums.sum(0, keepdim=True)\n",
    "        \n",
    "        idx = torch.multinomial(prob, num_samples=1, replacement=True).item()\n",
    "        word.append(itos_labels[idx])\n",
    "        chars += itos_labels[idx]\n",
    "        if chars[-1] == \".\":\n",
    "            break\n",
    "    print(\"\".join(word))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " split up the dataset randomly into 80% train set, 10% dev set, 10% test set. Train the bigram and trigram models only on the training set. Evaluate them on dev and test splits. What can you see?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data[: int(0.8 * len(data))]\n",
    "test_data = data[int(0.8 * len(data)): int(0.9 * len(data))]\n",
    "val_data = data[int(0.9 * len(data)):]\n",
    "\n",
    "train_labels = labels[: int(0.8 * len(labels))]\n",
    "test_labels = labels[int(0.8 * len(labels)): int(0.9 * len(labels))]\n",
    "val_labels = labels[int(0.9 * len(labels)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch\n",
    "encoding_size = len(stoi_data.keys())\n",
    "\n",
    "encoded = F.one_hot(torch.tensor(train_data), encoding_size).float()\n",
    "W = torch.randn((encoding_size, 27), requires_grad=True).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.7581, grad_fn=<NegBackward0>)\n",
      "tensor(3.6580, grad_fn=<NegBackward0>)\n",
      "tensor(3.5788, grad_fn=<NegBackward0>)\n",
      "tensor(3.5101, grad_fn=<NegBackward0>)\n",
      "tensor(3.4488, grad_fn=<NegBackward0>)\n",
      "tensor(3.3934, grad_fn=<NegBackward0>)\n",
      "tensor(3.3432, grad_fn=<NegBackward0>)\n",
      "tensor(3.2975, grad_fn=<NegBackward0>)\n",
      "tensor(3.2558, grad_fn=<NegBackward0>)\n",
      "tensor(3.2176, grad_fn=<NegBackward0>)\n",
      "tensor(3.1826, grad_fn=<NegBackward0>)\n",
      "tensor(3.1503, grad_fn=<NegBackward0>)\n",
      "tensor(3.1205, grad_fn=<NegBackward0>)\n",
      "tensor(3.0928, grad_fn=<NegBackward0>)\n",
      "tensor(3.0670, grad_fn=<NegBackward0>)\n",
      "tensor(3.0429, grad_fn=<NegBackward0>)\n",
      "tensor(3.0203, grad_fn=<NegBackward0>)\n",
      "tensor(2.9990, grad_fn=<NegBackward0>)\n",
      "tensor(2.9790, grad_fn=<NegBackward0>)\n",
      "tensor(2.9601, grad_fn=<NegBackward0>)\n",
      "tensor(2.9423, grad_fn=<NegBackward0>)\n",
      "tensor(2.9253, grad_fn=<NegBackward0>)\n",
      "tensor(2.9093, grad_fn=<NegBackward0>)\n",
      "tensor(2.8940, grad_fn=<NegBackward0>)\n",
      "tensor(2.8795, grad_fn=<NegBackward0>)\n",
      "tensor(2.8657, grad_fn=<NegBackward0>)\n",
      "tensor(2.8524, grad_fn=<NegBackward0>)\n",
      "tensor(2.8398, grad_fn=<NegBackward0>)\n",
      "tensor(2.8277, grad_fn=<NegBackward0>)\n",
      "tensor(2.8161, grad_fn=<NegBackward0>)\n",
      "tensor(2.8050, grad_fn=<NegBackward0>)\n",
      "tensor(2.7943, grad_fn=<NegBackward0>)\n",
      "tensor(2.7840, grad_fn=<NegBackward0>)\n",
      "tensor(2.7741, grad_fn=<NegBackward0>)\n",
      "tensor(2.7646, grad_fn=<NegBackward0>)\n",
      "tensor(2.7554, grad_fn=<NegBackward0>)\n",
      "tensor(2.7465, grad_fn=<NegBackward0>)\n",
      "tensor(2.7379, grad_fn=<NegBackward0>)\n",
      "tensor(2.7295, grad_fn=<NegBackward0>)\n",
      "tensor(2.7215, grad_fn=<NegBackward0>)\n",
      "tensor(2.7137, grad_fn=<NegBackward0>)\n",
      "tensor(2.7061, grad_fn=<NegBackward0>)\n",
      "tensor(2.6987, grad_fn=<NegBackward0>)\n",
      "tensor(2.6916, grad_fn=<NegBackward0>)\n",
      "tensor(2.6847, grad_fn=<NegBackward0>)\n",
      "tensor(2.6779, grad_fn=<NegBackward0>)\n",
      "tensor(2.6714, grad_fn=<NegBackward0>)\n",
      "tensor(2.6650, grad_fn=<NegBackward0>)\n",
      "tensor(2.6588, grad_fn=<NegBackward0>)\n",
      "tensor(2.6527, grad_fn=<NegBackward0>)\n",
      "tensor(2.6468, grad_fn=<NegBackward0>)\n",
      "tensor(2.6410, grad_fn=<NegBackward0>)\n",
      "tensor(2.6354, grad_fn=<NegBackward0>)\n",
      "tensor(2.6300, grad_fn=<NegBackward0>)\n",
      "tensor(2.6246, grad_fn=<NegBackward0>)\n",
      "tensor(2.6194, grad_fn=<NegBackward0>)\n",
      "tensor(2.6143, grad_fn=<NegBackward0>)\n",
      "tensor(2.6093, grad_fn=<NegBackward0>)\n",
      "tensor(2.6044, grad_fn=<NegBackward0>)\n",
      "tensor(2.5997, grad_fn=<NegBackward0>)\n",
      "tensor(2.5950, grad_fn=<NegBackward0>)\n",
      "tensor(2.5905, grad_fn=<NegBackward0>)\n",
      "tensor(2.5860, grad_fn=<NegBackward0>)\n",
      "tensor(2.5817, grad_fn=<NegBackward0>)\n",
      "tensor(2.5774, grad_fn=<NegBackward0>)\n",
      "tensor(2.5732, grad_fn=<NegBackward0>)\n",
      "tensor(2.5692, grad_fn=<NegBackward0>)\n",
      "tensor(2.5652, grad_fn=<NegBackward0>)\n",
      "tensor(2.5612, grad_fn=<NegBackward0>)\n",
      "tensor(2.5574, grad_fn=<NegBackward0>)\n",
      "tensor(2.5536, grad_fn=<NegBackward0>)\n",
      "tensor(2.5499, grad_fn=<NegBackward0>)\n",
      "tensor(2.5463, grad_fn=<NegBackward0>)\n",
      "tensor(2.5428, grad_fn=<NegBackward0>)\n",
      "tensor(2.5393, grad_fn=<NegBackward0>)\n",
      "tensor(2.5359, grad_fn=<NegBackward0>)\n",
      "tensor(2.5325, grad_fn=<NegBackward0>)\n",
      "tensor(2.5292, grad_fn=<NegBackward0>)\n",
      "tensor(2.5260, grad_fn=<NegBackward0>)\n",
      "tensor(2.5228, grad_fn=<NegBackward0>)\n",
      "tensor(2.5197, grad_fn=<NegBackward0>)\n",
      "tensor(2.5166, grad_fn=<NegBackward0>)\n",
      "tensor(2.5136, grad_fn=<NegBackward0>)\n",
      "tensor(2.5107, grad_fn=<NegBackward0>)\n",
      "tensor(2.5078, grad_fn=<NegBackward0>)\n",
      "tensor(2.5049, grad_fn=<NegBackward0>)\n",
      "tensor(2.5021, grad_fn=<NegBackward0>)\n",
      "tensor(2.4994, grad_fn=<NegBackward0>)\n",
      "tensor(2.4967, grad_fn=<NegBackward0>)\n",
      "tensor(2.4940, grad_fn=<NegBackward0>)\n",
      "tensor(2.4914, grad_fn=<NegBackward0>)\n",
      "tensor(2.4888, grad_fn=<NegBackward0>)\n",
      "tensor(2.4863, grad_fn=<NegBackward0>)\n",
      "tensor(2.4838, grad_fn=<NegBackward0>)\n",
      "tensor(2.4813, grad_fn=<NegBackward0>)\n",
      "tensor(2.4789, grad_fn=<NegBackward0>)\n",
      "tensor(2.4765, grad_fn=<NegBackward0>)\n",
      "tensor(2.4742, grad_fn=<NegBackward0>)\n",
      "tensor(2.4719, grad_fn=<NegBackward0>)\n",
      "tensor(2.4696, grad_fn=<NegBackward0>)\n",
      "tensor(2.4674, grad_fn=<NegBackward0>)\n",
      "tensor(2.4652, grad_fn=<NegBackward0>)\n",
      "tensor(2.4630, grad_fn=<NegBackward0>)\n",
      "tensor(2.4608, grad_fn=<NegBackward0>)\n",
      "tensor(2.4587, grad_fn=<NegBackward0>)\n",
      "tensor(2.4567, grad_fn=<NegBackward0>)\n",
      "tensor(2.4546, grad_fn=<NegBackward0>)\n",
      "tensor(2.4526, grad_fn=<NegBackward0>)\n",
      "tensor(2.4506, grad_fn=<NegBackward0>)\n",
      "tensor(2.4486, grad_fn=<NegBackward0>)\n",
      "tensor(2.4467, grad_fn=<NegBackward0>)\n",
      "tensor(2.4448, grad_fn=<NegBackward0>)\n",
      "tensor(2.4429, grad_fn=<NegBackward0>)\n",
      "tensor(2.4411, grad_fn=<NegBackward0>)\n",
      "tensor(2.4392, grad_fn=<NegBackward0>)\n",
      "tensor(2.4374, grad_fn=<NegBackward0>)\n",
      "tensor(2.4356, grad_fn=<NegBackward0>)\n",
      "tensor(2.4339, grad_fn=<NegBackward0>)\n",
      "tensor(2.4321, grad_fn=<NegBackward0>)\n",
      "tensor(2.4304, grad_fn=<NegBackward0>)\n",
      "tensor(2.4287, grad_fn=<NegBackward0>)\n",
      "tensor(2.4271, grad_fn=<NegBackward0>)\n",
      "tensor(2.4254, grad_fn=<NegBackward0>)\n",
      "tensor(2.4238, grad_fn=<NegBackward0>)\n",
      "tensor(2.4222, grad_fn=<NegBackward0>)\n",
      "tensor(2.4206, grad_fn=<NegBackward0>)\n",
      "tensor(2.4190, grad_fn=<NegBackward0>)\n",
      "tensor(2.4175, grad_fn=<NegBackward0>)\n",
      "tensor(2.4159, grad_fn=<NegBackward0>)\n",
      "tensor(2.4144, grad_fn=<NegBackward0>)\n",
      "tensor(2.4129, grad_fn=<NegBackward0>)\n",
      "tensor(2.4114, grad_fn=<NegBackward0>)\n",
      "tensor(2.4100, grad_fn=<NegBackward0>)\n",
      "tensor(2.4085, grad_fn=<NegBackward0>)\n",
      "tensor(2.4071, grad_fn=<NegBackward0>)\n",
      "tensor(2.4057, grad_fn=<NegBackward0>)\n",
      "tensor(2.4043, grad_fn=<NegBackward0>)\n",
      "tensor(2.4029, grad_fn=<NegBackward0>)\n",
      "tensor(2.4016, grad_fn=<NegBackward0>)\n",
      "tensor(2.4002, grad_fn=<NegBackward0>)\n",
      "tensor(2.3989, grad_fn=<NegBackward0>)\n",
      "tensor(2.3976, grad_fn=<NegBackward0>)\n",
      "tensor(2.3962, grad_fn=<NegBackward0>)\n",
      "tensor(2.3950, grad_fn=<NegBackward0>)\n",
      "tensor(2.3937, grad_fn=<NegBackward0>)\n",
      "tensor(2.3924, grad_fn=<NegBackward0>)\n",
      "tensor(2.3912, grad_fn=<NegBackward0>)\n",
      "tensor(2.3899, grad_fn=<NegBackward0>)\n",
      "tensor(2.3887, grad_fn=<NegBackward0>)\n",
      "tensor(2.3875, grad_fn=<NegBackward0>)\n",
      "tensor(2.3863, grad_fn=<NegBackward0>)\n",
      "tensor(2.3851, grad_fn=<NegBackward0>)\n",
      "tensor(2.3840, grad_fn=<NegBackward0>)\n",
      "tensor(2.3828, grad_fn=<NegBackward0>)\n",
      "tensor(2.3816, grad_fn=<NegBackward0>)\n",
      "tensor(2.3805, grad_fn=<NegBackward0>)\n",
      "tensor(2.3794, grad_fn=<NegBackward0>)\n",
      "tensor(2.3783, grad_fn=<NegBackward0>)\n",
      "tensor(2.3772, grad_fn=<NegBackward0>)\n",
      "tensor(2.3761, grad_fn=<NegBackward0>)\n",
      "tensor(2.3750, grad_fn=<NegBackward0>)\n",
      "tensor(2.3739, grad_fn=<NegBackward0>)\n",
      "tensor(2.3729, grad_fn=<NegBackward0>)\n",
      "tensor(2.3718, grad_fn=<NegBackward0>)\n",
      "tensor(2.3708, grad_fn=<NegBackward0>)\n",
      "tensor(2.3697, grad_fn=<NegBackward0>)\n",
      "tensor(2.3687, grad_fn=<NegBackward0>)\n",
      "tensor(2.3677, grad_fn=<NegBackward0>)\n",
      "tensor(2.3667, grad_fn=<NegBackward0>)\n",
      "tensor(2.3657, grad_fn=<NegBackward0>)\n",
      "tensor(2.3647, grad_fn=<NegBackward0>)\n",
      "tensor(2.3638, grad_fn=<NegBackward0>)\n",
      "tensor(2.3628, grad_fn=<NegBackward0>)\n",
      "tensor(2.3619, grad_fn=<NegBackward0>)\n",
      "tensor(2.3609, grad_fn=<NegBackward0>)\n",
      "tensor(2.3600, grad_fn=<NegBackward0>)\n",
      "tensor(2.3590, grad_fn=<NegBackward0>)\n",
      "tensor(2.3581, grad_fn=<NegBackward0>)\n",
      "tensor(2.3572, grad_fn=<NegBackward0>)\n",
      "tensor(2.3563, grad_fn=<NegBackward0>)\n",
      "tensor(2.3554, grad_fn=<NegBackward0>)\n",
      "tensor(2.3545, grad_fn=<NegBackward0>)\n",
      "tensor(2.3536, grad_fn=<NegBackward0>)\n",
      "tensor(2.3528, grad_fn=<NegBackward0>)\n",
      "tensor(2.3519, grad_fn=<NegBackward0>)\n",
      "tensor(2.3511, grad_fn=<NegBackward0>)\n",
      "tensor(2.3502, grad_fn=<NegBackward0>)\n",
      "tensor(2.3494, grad_fn=<NegBackward0>)\n",
      "tensor(2.3485, grad_fn=<NegBackward0>)\n",
      "tensor(2.3477, grad_fn=<NegBackward0>)\n",
      "tensor(2.3469, grad_fn=<NegBackward0>)\n",
      "tensor(2.3461, grad_fn=<NegBackward0>)\n",
      "tensor(2.3453, grad_fn=<NegBackward0>)\n",
      "tensor(2.3445, grad_fn=<NegBackward0>)\n",
      "tensor(2.3437, grad_fn=<NegBackward0>)\n",
      "tensor(2.3429, grad_fn=<NegBackward0>)\n",
      "tensor(2.3421, grad_fn=<NegBackward0>)\n",
      "tensor(2.3413, grad_fn=<NegBackward0>)\n",
      "tensor(2.3406, grad_fn=<NegBackward0>)\n",
      "tensor(2.3398, grad_fn=<NegBackward0>)\n",
      "tensor(2.3390, grad_fn=<NegBackward0>)\n",
      "tensor(2.3383, grad_fn=<NegBackward0>)\n",
      "tensor(2.3376, grad_fn=<NegBackward0>)\n",
      "tensor(2.3368, grad_fn=<NegBackward0>)\n",
      "tensor(2.3361, grad_fn=<NegBackward0>)\n",
      "tensor(2.3354, grad_fn=<NegBackward0>)\n",
      "tensor(2.3346, grad_fn=<NegBackward0>)\n",
      "tensor(2.3339, grad_fn=<NegBackward0>)\n",
      "tensor(2.3332, grad_fn=<NegBackward0>)\n",
      "tensor(2.3325, grad_fn=<NegBackward0>)\n",
      "tensor(2.3318, grad_fn=<NegBackward0>)\n",
      "tensor(2.3311, grad_fn=<NegBackward0>)\n",
      "tensor(2.3304, grad_fn=<NegBackward0>)\n",
      "tensor(2.3298, grad_fn=<NegBackward0>)\n",
      "tensor(2.3291, grad_fn=<NegBackward0>)\n",
      "tensor(2.3284, grad_fn=<NegBackward0>)\n",
      "tensor(2.3278, grad_fn=<NegBackward0>)\n",
      "tensor(2.3271, grad_fn=<NegBackward0>)\n",
      "tensor(2.3264, grad_fn=<NegBackward0>)\n",
      "tensor(2.3258, grad_fn=<NegBackward0>)\n",
      "tensor(2.3251, grad_fn=<NegBackward0>)\n",
      "tensor(2.3245, grad_fn=<NegBackward0>)\n",
      "tensor(2.3239, grad_fn=<NegBackward0>)\n",
      "tensor(2.3232, grad_fn=<NegBackward0>)\n",
      "tensor(2.3226, grad_fn=<NegBackward0>)\n",
      "tensor(2.3220, grad_fn=<NegBackward0>)\n",
      "tensor(2.3214, grad_fn=<NegBackward0>)\n",
      "tensor(2.3208, grad_fn=<NegBackward0>)\n",
      "tensor(2.3202, grad_fn=<NegBackward0>)\n",
      "tensor(2.3196, grad_fn=<NegBackward0>)\n",
      "tensor(2.3190, grad_fn=<NegBackward0>)\n",
      "tensor(2.3184, grad_fn=<NegBackward0>)\n",
      "tensor(2.3178, grad_fn=<NegBackward0>)\n",
      "tensor(2.3172, grad_fn=<NegBackward0>)\n",
      "tensor(2.3166, grad_fn=<NegBackward0>)\n",
      "tensor(2.3160, grad_fn=<NegBackward0>)\n",
      "tensor(2.3155, grad_fn=<NegBackward0>)\n",
      "tensor(2.3149, grad_fn=<NegBackward0>)\n",
      "tensor(2.3143, grad_fn=<NegBackward0>)\n",
      "tensor(2.3138, grad_fn=<NegBackward0>)\n",
      "tensor(2.3132, grad_fn=<NegBackward0>)\n",
      "tensor(2.3126, grad_fn=<NegBackward0>)\n",
      "tensor(2.3121, grad_fn=<NegBackward0>)\n",
      "tensor(2.3115, grad_fn=<NegBackward0>)\n",
      "tensor(2.3110, grad_fn=<NegBackward0>)\n",
      "tensor(2.3105, grad_fn=<NegBackward0>)\n",
      "tensor(2.3099, grad_fn=<NegBackward0>)\n",
      "tensor(2.3094, grad_fn=<NegBackward0>)\n",
      "tensor(2.3089, grad_fn=<NegBackward0>)\n",
      "tensor(2.3083, grad_fn=<NegBackward0>)\n",
      "tensor(2.3078, grad_fn=<NegBackward0>)\n",
      "tensor(2.3073, grad_fn=<NegBackward0>)\n",
      "tensor(2.3068, grad_fn=<NegBackward0>)\n",
      "tensor(2.3063, grad_fn=<NegBackward0>)\n",
      "tensor(2.3058, grad_fn=<NegBackward0>)\n",
      "tensor(2.3053, grad_fn=<NegBackward0>)\n",
      "tensor(2.3048, grad_fn=<NegBackward0>)\n",
      "tensor(2.3043, grad_fn=<NegBackward0>)\n",
      "tensor(2.3038, grad_fn=<NegBackward0>)\n",
      "tensor(2.3033, grad_fn=<NegBackward0>)\n",
      "tensor(2.3028, grad_fn=<NegBackward0>)\n",
      "tensor(2.3023, grad_fn=<NegBackward0>)\n",
      "tensor(2.3018, grad_fn=<NegBackward0>)\n",
      "tensor(2.3014, grad_fn=<NegBackward0>)\n",
      "tensor(2.3009, grad_fn=<NegBackward0>)\n",
      "tensor(2.3004, grad_fn=<NegBackward0>)\n",
      "tensor(2.2999, grad_fn=<NegBackward0>)\n",
      "tensor(2.2995, grad_fn=<NegBackward0>)\n",
      "tensor(2.2990, grad_fn=<NegBackward0>)\n",
      "tensor(2.2985, grad_fn=<NegBackward0>)\n",
      "tensor(2.2981, grad_fn=<NegBackward0>)\n",
      "tensor(2.2976, grad_fn=<NegBackward0>)\n",
      "tensor(2.2972, grad_fn=<NegBackward0>)\n",
      "tensor(2.2967, grad_fn=<NegBackward0>)\n",
      "tensor(2.2963, grad_fn=<NegBackward0>)\n",
      "tensor(2.2958, grad_fn=<NegBackward0>)\n",
      "tensor(2.2954, grad_fn=<NegBackward0>)\n",
      "tensor(2.2950, grad_fn=<NegBackward0>)\n",
      "tensor(2.2945, grad_fn=<NegBackward0>)\n",
      "tensor(2.2941, grad_fn=<NegBackward0>)\n",
      "tensor(2.2937, grad_fn=<NegBackward0>)\n",
      "tensor(2.2932, grad_fn=<NegBackward0>)\n",
      "tensor(2.2928, grad_fn=<NegBackward0>)\n",
      "tensor(2.2924, grad_fn=<NegBackward0>)\n",
      "tensor(2.2920, grad_fn=<NegBackward0>)\n",
      "tensor(2.2916, grad_fn=<NegBackward0>)\n",
      "tensor(2.2911, grad_fn=<NegBackward0>)\n",
      "tensor(2.2907, grad_fn=<NegBackward0>)\n",
      "tensor(2.2903, grad_fn=<NegBackward0>)\n",
      "tensor(2.2899, grad_fn=<NegBackward0>)\n",
      "tensor(2.2895, grad_fn=<NegBackward0>)\n",
      "tensor(2.2891, grad_fn=<NegBackward0>)\n",
      "tensor(2.2887, grad_fn=<NegBackward0>)\n",
      "tensor(2.2883, grad_fn=<NegBackward0>)\n",
      "tensor(2.2879, grad_fn=<NegBackward0>)\n",
      "tensor(2.2875, grad_fn=<NegBackward0>)\n",
      "tensor(2.2871, grad_fn=<NegBackward0>)\n",
      "tensor(2.2867, grad_fn=<NegBackward0>)\n",
      "tensor(2.2863, grad_fn=<NegBackward0>)\n",
      "tensor(2.2860, grad_fn=<NegBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for i in range(300):\n",
    "    logits = (encoded @ W)\n",
    "    counts = logits.exp()\n",
    "    probs = counts / counts.sum(1, keepdim=True)\n",
    "\n",
    "    loss = -probs[torch.arange(len(train_labels)), train_labels].log().mean()\n",
    "\n",
    "    W.grad = None\n",
    "    loss.backward()\n",
    "    W.data += -W.grad * 50\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = F.one_hot(torch.tensor(test_data), encoding_size).float()\n",
    "\n",
    "logits = (encoded @ W)\n",
    "counts = logits.exp()\n",
    "probs = counts / counts.sum(1, keepdim=True)\n",
    "\n",
    "loss = -probs[torch.arange(len(test_labels)), test_labels].log().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3862, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E03: use the dev set to tune the strength of smoothing (or regularization) for the trigram model - i.e. try many possibilities and see which one works best based on the dev set loss. What patterns can you see in the train and dev set loss as you tune this strength? Take the best setting of the smoothing and evaluate on the test set once and at the end. How good of a loss do you achieve?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.6203, grad_fn=<AddBackward0>)\n",
      "tensor(2.6037, grad_fn=<AddBackward0>)\n",
      "tensor(2.5925, grad_fn=<AddBackward0>)\n",
      "tensor(2.5836, grad_fn=<AddBackward0>)\n",
      "tensor(2.5760, grad_fn=<AddBackward0>)\n",
      "tensor(2.5693, grad_fn=<AddBackward0>)\n",
      "tensor(2.5633, grad_fn=<AddBackward0>)\n",
      "tensor(2.5578, grad_fn=<AddBackward0>)\n",
      "tensor(2.5527, grad_fn=<AddBackward0>)\n",
      "tensor(2.5479, grad_fn=<AddBackward0>)\n",
      "tensor(2.5435, grad_fn=<AddBackward0>)\n",
      "tensor(2.5393, grad_fn=<AddBackward0>)\n",
      "tensor(2.5354, grad_fn=<AddBackward0>)\n",
      "tensor(2.5316, grad_fn=<AddBackward0>)\n",
      "tensor(2.5280, grad_fn=<AddBackward0>)\n",
      "tensor(2.5246, grad_fn=<AddBackward0>)\n",
      "tensor(2.5214, grad_fn=<AddBackward0>)\n",
      "tensor(2.5183, grad_fn=<AddBackward0>)\n",
      "tensor(2.5153, grad_fn=<AddBackward0>)\n",
      "tensor(2.5124, grad_fn=<AddBackward0>)\n",
      "tensor(2.5096, grad_fn=<AddBackward0>)\n",
      "tensor(2.5069, grad_fn=<AddBackward0>)\n",
      "tensor(2.5043, grad_fn=<AddBackward0>)\n",
      "tensor(2.5018, grad_fn=<AddBackward0>)\n",
      "tensor(2.4994, grad_fn=<AddBackward0>)\n",
      "tensor(2.4971, grad_fn=<AddBackward0>)\n",
      "tensor(2.4948, grad_fn=<AddBackward0>)\n",
      "tensor(2.4926, grad_fn=<AddBackward0>)\n",
      "tensor(2.4904, grad_fn=<AddBackward0>)\n",
      "tensor(2.4883, grad_fn=<AddBackward0>)\n",
      "tensor(2.4863, grad_fn=<AddBackward0>)\n",
      "tensor(2.4843, grad_fn=<AddBackward0>)\n",
      "tensor(2.4823, grad_fn=<AddBackward0>)\n",
      "tensor(2.4804, grad_fn=<AddBackward0>)\n",
      "tensor(2.4786, grad_fn=<AddBackward0>)\n",
      "tensor(2.4768, grad_fn=<AddBackward0>)\n",
      "tensor(2.4750, grad_fn=<AddBackward0>)\n",
      "tensor(2.4733, grad_fn=<AddBackward0>)\n",
      "tensor(2.4716, grad_fn=<AddBackward0>)\n",
      "tensor(2.4700, grad_fn=<AddBackward0>)\n",
      "tensor(2.4683, grad_fn=<AddBackward0>)\n",
      "tensor(2.4667, grad_fn=<AddBackward0>)\n",
      "tensor(2.4652, grad_fn=<AddBackward0>)\n",
      "tensor(2.4637, grad_fn=<AddBackward0>)\n",
      "tensor(2.4622, grad_fn=<AddBackward0>)\n",
      "tensor(2.4607, grad_fn=<AddBackward0>)\n",
      "tensor(2.4592, grad_fn=<AddBackward0>)\n",
      "tensor(2.4578, grad_fn=<AddBackward0>)\n",
      "tensor(2.4564, grad_fn=<AddBackward0>)\n",
      "tensor(2.4551, grad_fn=<AddBackward0>)\n",
      "tensor(2.4537, grad_fn=<AddBackward0>)\n",
      "tensor(2.4524, grad_fn=<AddBackward0>)\n",
      "tensor(2.4511, grad_fn=<AddBackward0>)\n",
      "tensor(2.4498, grad_fn=<AddBackward0>)\n",
      "tensor(2.4485, grad_fn=<AddBackward0>)\n",
      "tensor(2.4473, grad_fn=<AddBackward0>)\n",
      "tensor(2.4461, grad_fn=<AddBackward0>)\n",
      "tensor(2.4449, grad_fn=<AddBackward0>)\n",
      "tensor(2.4437, grad_fn=<AddBackward0>)\n",
      "tensor(2.4425, grad_fn=<AddBackward0>)\n",
      "tensor(2.4413, grad_fn=<AddBackward0>)\n",
      "tensor(2.4402, grad_fn=<AddBackward0>)\n",
      "tensor(2.4391, grad_fn=<AddBackward0>)\n",
      "tensor(2.4380, grad_fn=<AddBackward0>)\n",
      "tensor(2.4369, grad_fn=<AddBackward0>)\n",
      "tensor(2.4358, grad_fn=<AddBackward0>)\n",
      "tensor(2.4347, grad_fn=<AddBackward0>)\n",
      "tensor(2.4337, grad_fn=<AddBackward0>)\n",
      "tensor(2.4327, grad_fn=<AddBackward0>)\n",
      "tensor(2.4316, grad_fn=<AddBackward0>)\n",
      "tensor(2.4306, grad_fn=<AddBackward0>)\n",
      "tensor(2.4296, grad_fn=<AddBackward0>)\n",
      "tensor(2.4287, grad_fn=<AddBackward0>)\n",
      "tensor(2.4277, grad_fn=<AddBackward0>)\n",
      "tensor(2.4267, grad_fn=<AddBackward0>)\n",
      "tensor(2.4258, grad_fn=<AddBackward0>)\n",
      "tensor(2.4248, grad_fn=<AddBackward0>)\n",
      "tensor(2.4239, grad_fn=<AddBackward0>)\n",
      "tensor(2.4230, grad_fn=<AddBackward0>)\n",
      "tensor(2.4221, grad_fn=<AddBackward0>)\n",
      "tensor(2.4212, grad_fn=<AddBackward0>)\n",
      "tensor(2.4203, grad_fn=<AddBackward0>)\n",
      "tensor(2.4194, grad_fn=<AddBackward0>)\n",
      "tensor(2.4185, grad_fn=<AddBackward0>)\n",
      "tensor(2.4177, grad_fn=<AddBackward0>)\n",
      "tensor(2.4168, grad_fn=<AddBackward0>)\n",
      "tensor(2.4160, grad_fn=<AddBackward0>)\n",
      "tensor(2.4152, grad_fn=<AddBackward0>)\n",
      "tensor(2.4143, grad_fn=<AddBackward0>)\n",
      "tensor(2.4135, grad_fn=<AddBackward0>)\n",
      "tensor(2.4127, grad_fn=<AddBackward0>)\n",
      "tensor(2.4119, grad_fn=<AddBackward0>)\n",
      "tensor(2.4111, grad_fn=<AddBackward0>)\n",
      "tensor(2.4104, grad_fn=<AddBackward0>)\n",
      "tensor(2.4096, grad_fn=<AddBackward0>)\n",
      "tensor(2.4088, grad_fn=<AddBackward0>)\n",
      "tensor(2.4081, grad_fn=<AddBackward0>)\n",
      "tensor(2.4073, grad_fn=<AddBackward0>)\n",
      "tensor(2.4066, grad_fn=<AddBackward0>)\n",
      "tensor(2.4058, grad_fn=<AddBackward0>)\n",
      "tensor(2.4051, grad_fn=<AddBackward0>)\n",
      "tensor(2.4044, grad_fn=<AddBackward0>)\n",
      "tensor(2.4037, grad_fn=<AddBackward0>)\n",
      "tensor(2.4029, grad_fn=<AddBackward0>)\n",
      "tensor(2.4022, grad_fn=<AddBackward0>)\n",
      "tensor(2.4015, grad_fn=<AddBackward0>)\n",
      "tensor(2.4008, grad_fn=<AddBackward0>)\n",
      "tensor(2.4002, grad_fn=<AddBackward0>)\n",
      "tensor(2.3995, grad_fn=<AddBackward0>)\n",
      "tensor(2.3988, grad_fn=<AddBackward0>)\n",
      "tensor(2.3981, grad_fn=<AddBackward0>)\n",
      "tensor(2.3975, grad_fn=<AddBackward0>)\n",
      "tensor(2.3968, grad_fn=<AddBackward0>)\n",
      "tensor(2.3962, grad_fn=<AddBackward0>)\n",
      "tensor(2.3955, grad_fn=<AddBackward0>)\n",
      "tensor(2.3949, grad_fn=<AddBackward0>)\n",
      "tensor(2.3942, grad_fn=<AddBackward0>)\n",
      "tensor(2.3936, grad_fn=<AddBackward0>)\n",
      "tensor(2.3930, grad_fn=<AddBackward0>)\n",
      "tensor(2.3924, grad_fn=<AddBackward0>)\n",
      "tensor(2.3917, grad_fn=<AddBackward0>)\n",
      "tensor(2.3911, grad_fn=<AddBackward0>)\n",
      "tensor(2.3905, grad_fn=<AddBackward0>)\n",
      "tensor(2.3899, grad_fn=<AddBackward0>)\n",
      "tensor(2.3893, grad_fn=<AddBackward0>)\n",
      "tensor(2.3887, grad_fn=<AddBackward0>)\n",
      "tensor(2.3882, grad_fn=<AddBackward0>)\n",
      "tensor(2.3876, grad_fn=<AddBackward0>)\n",
      "tensor(2.3870, grad_fn=<AddBackward0>)\n",
      "tensor(2.3864, grad_fn=<AddBackward0>)\n",
      "tensor(2.3858, grad_fn=<AddBackward0>)\n",
      "tensor(2.3853, grad_fn=<AddBackward0>)\n",
      "tensor(2.3847, grad_fn=<AddBackward0>)\n",
      "tensor(2.3842, grad_fn=<AddBackward0>)\n",
      "tensor(2.3836, grad_fn=<AddBackward0>)\n",
      "tensor(2.3831, grad_fn=<AddBackward0>)\n",
      "tensor(2.3825, grad_fn=<AddBackward0>)\n",
      "tensor(2.3820, grad_fn=<AddBackward0>)\n",
      "tensor(2.3814, grad_fn=<AddBackward0>)\n",
      "tensor(2.3809, grad_fn=<AddBackward0>)\n",
      "tensor(2.3804, grad_fn=<AddBackward0>)\n",
      "tensor(2.3798, grad_fn=<AddBackward0>)\n",
      "tensor(2.3793, grad_fn=<AddBackward0>)\n",
      "tensor(2.3788, grad_fn=<AddBackward0>)\n",
      "tensor(2.3783, grad_fn=<AddBackward0>)\n",
      "tensor(2.3778, grad_fn=<AddBackward0>)\n",
      "tensor(2.3773, grad_fn=<AddBackward0>)\n",
      "tensor(2.3768, grad_fn=<AddBackward0>)\n",
      "tensor(2.3762, grad_fn=<AddBackward0>)\n",
      "tensor(2.3757, grad_fn=<AddBackward0>)\n",
      "tensor(2.3753, grad_fn=<AddBackward0>)\n",
      "tensor(2.3748, grad_fn=<AddBackward0>)\n",
      "tensor(2.3743, grad_fn=<AddBackward0>)\n",
      "tensor(2.3738, grad_fn=<AddBackward0>)\n",
      "tensor(2.3733, grad_fn=<AddBackward0>)\n",
      "tensor(2.3728, grad_fn=<AddBackward0>)\n",
      "tensor(2.3723, grad_fn=<AddBackward0>)\n",
      "tensor(2.3719, grad_fn=<AddBackward0>)\n",
      "tensor(2.3714, grad_fn=<AddBackward0>)\n",
      "tensor(2.3709, grad_fn=<AddBackward0>)\n",
      "tensor(2.3705, grad_fn=<AddBackward0>)\n",
      "tensor(2.3700, grad_fn=<AddBackward0>)\n",
      "tensor(2.3695, grad_fn=<AddBackward0>)\n",
      "tensor(2.3691, grad_fn=<AddBackward0>)\n",
      "tensor(2.3686, grad_fn=<AddBackward0>)\n",
      "tensor(2.3682, grad_fn=<AddBackward0>)\n",
      "tensor(2.3677, grad_fn=<AddBackward0>)\n",
      "tensor(2.3673, grad_fn=<AddBackward0>)\n",
      "tensor(2.3669, grad_fn=<AddBackward0>)\n",
      "tensor(2.3664, grad_fn=<AddBackward0>)\n",
      "tensor(2.3660, grad_fn=<AddBackward0>)\n",
      "tensor(2.3655, grad_fn=<AddBackward0>)\n",
      "tensor(2.3651, grad_fn=<AddBackward0>)\n",
      "tensor(2.3647, grad_fn=<AddBackward0>)\n",
      "tensor(2.3643, grad_fn=<AddBackward0>)\n",
      "tensor(2.3638, grad_fn=<AddBackward0>)\n",
      "tensor(2.3634, grad_fn=<AddBackward0>)\n",
      "tensor(2.3630, grad_fn=<AddBackward0>)\n",
      "tensor(2.3626, grad_fn=<AddBackward0>)\n",
      "tensor(2.3622, grad_fn=<AddBackward0>)\n",
      "tensor(2.3617, grad_fn=<AddBackward0>)\n",
      "tensor(2.3613, grad_fn=<AddBackward0>)\n",
      "tensor(2.3609, grad_fn=<AddBackward0>)\n",
      "tensor(2.3605, grad_fn=<AddBackward0>)\n",
      "tensor(2.3601, grad_fn=<AddBackward0>)\n",
      "tensor(2.3597, grad_fn=<AddBackward0>)\n",
      "tensor(2.3593, grad_fn=<AddBackward0>)\n",
      "tensor(2.3589, grad_fn=<AddBackward0>)\n",
      "tensor(2.3585, grad_fn=<AddBackward0>)\n",
      "tensor(2.3581, grad_fn=<AddBackward0>)\n",
      "tensor(2.3578, grad_fn=<AddBackward0>)\n",
      "tensor(2.3574, grad_fn=<AddBackward0>)\n",
      "tensor(2.3570, grad_fn=<AddBackward0>)\n",
      "tensor(2.3566, grad_fn=<AddBackward0>)\n",
      "tensor(2.3562, grad_fn=<AddBackward0>)\n",
      "tensor(2.3558, grad_fn=<AddBackward0>)\n",
      "tensor(2.3555, grad_fn=<AddBackward0>)\n",
      "tensor(2.3551, grad_fn=<AddBackward0>)\n",
      "tensor(2.3547, grad_fn=<AddBackward0>)\n",
      "tensor(2.3543, grad_fn=<AddBackward0>)\n",
      "tensor(2.3540, grad_fn=<AddBackward0>)\n",
      "tensor(2.3536, grad_fn=<AddBackward0>)\n",
      "tensor(2.3532, grad_fn=<AddBackward0>)\n",
      "tensor(2.3529, grad_fn=<AddBackward0>)\n",
      "tensor(2.3525, grad_fn=<AddBackward0>)\n",
      "tensor(2.3522, grad_fn=<AddBackward0>)\n",
      "tensor(2.3518, grad_fn=<AddBackward0>)\n",
      "tensor(2.3515, grad_fn=<AddBackward0>)\n",
      "tensor(2.3511, grad_fn=<AddBackward0>)\n",
      "tensor(2.3508, grad_fn=<AddBackward0>)\n",
      "tensor(2.3504, grad_fn=<AddBackward0>)\n",
      "tensor(2.3501, grad_fn=<AddBackward0>)\n",
      "tensor(2.3497, grad_fn=<AddBackward0>)\n",
      "tensor(2.3494, grad_fn=<AddBackward0>)\n",
      "tensor(2.3490, grad_fn=<AddBackward0>)\n",
      "tensor(2.3487, grad_fn=<AddBackward0>)\n",
      "tensor(2.3483, grad_fn=<AddBackward0>)\n",
      "tensor(2.3480, grad_fn=<AddBackward0>)\n",
      "tensor(2.3477, grad_fn=<AddBackward0>)\n",
      "tensor(2.3473, grad_fn=<AddBackward0>)\n",
      "tensor(2.3470, grad_fn=<AddBackward0>)\n",
      "tensor(2.3467, grad_fn=<AddBackward0>)\n",
      "tensor(2.3463, grad_fn=<AddBackward0>)\n",
      "tensor(2.3460, grad_fn=<AddBackward0>)\n",
      "tensor(2.3457, grad_fn=<AddBackward0>)\n",
      "tensor(2.3454, grad_fn=<AddBackward0>)\n",
      "tensor(2.3450, grad_fn=<AddBackward0>)\n",
      "tensor(2.3447, grad_fn=<AddBackward0>)\n",
      "tensor(2.3444, grad_fn=<AddBackward0>)\n",
      "tensor(2.3441, grad_fn=<AddBackward0>)\n",
      "tensor(2.3438, grad_fn=<AddBackward0>)\n",
      "tensor(2.3435, grad_fn=<AddBackward0>)\n",
      "tensor(2.3431, grad_fn=<AddBackward0>)\n",
      "tensor(2.3428, grad_fn=<AddBackward0>)\n",
      "tensor(2.3425, grad_fn=<AddBackward0>)\n",
      "tensor(2.3422, grad_fn=<AddBackward0>)\n",
      "tensor(2.3419, grad_fn=<AddBackward0>)\n",
      "tensor(2.3416, grad_fn=<AddBackward0>)\n",
      "tensor(2.3413, grad_fn=<AddBackward0>)\n",
      "tensor(2.3410, grad_fn=<AddBackward0>)\n",
      "tensor(2.3407, grad_fn=<AddBackward0>)\n",
      "tensor(2.3404, grad_fn=<AddBackward0>)\n",
      "tensor(2.3401, grad_fn=<AddBackward0>)\n",
      "tensor(2.3398, grad_fn=<AddBackward0>)\n",
      "tensor(2.3395, grad_fn=<AddBackward0>)\n",
      "tensor(2.3392, grad_fn=<AddBackward0>)\n",
      "tensor(2.3389, grad_fn=<AddBackward0>)\n",
      "tensor(2.3386, grad_fn=<AddBackward0>)\n",
      "tensor(2.3383, grad_fn=<AddBackward0>)\n",
      "tensor(2.3381, grad_fn=<AddBackward0>)\n",
      "tensor(2.3378, grad_fn=<AddBackward0>)\n",
      "tensor(2.3375, grad_fn=<AddBackward0>)\n",
      "tensor(2.3372, grad_fn=<AddBackward0>)\n",
      "tensor(2.3369, grad_fn=<AddBackward0>)\n",
      "tensor(2.3366, grad_fn=<AddBackward0>)\n",
      "tensor(2.3364, grad_fn=<AddBackward0>)\n",
      "tensor(2.3361, grad_fn=<AddBackward0>)\n",
      "tensor(2.3358, grad_fn=<AddBackward0>)\n",
      "tensor(2.3355, grad_fn=<AddBackward0>)\n",
      "tensor(2.3352, grad_fn=<AddBackward0>)\n",
      "tensor(2.3350, grad_fn=<AddBackward0>)\n",
      "tensor(2.3347, grad_fn=<AddBackward0>)\n",
      "tensor(2.3344, grad_fn=<AddBackward0>)\n",
      "tensor(2.3342, grad_fn=<AddBackward0>)\n",
      "tensor(2.3339, grad_fn=<AddBackward0>)\n",
      "tensor(2.3336, grad_fn=<AddBackward0>)\n",
      "tensor(2.3334, grad_fn=<AddBackward0>)\n",
      "tensor(2.3331, grad_fn=<AddBackward0>)\n",
      "tensor(2.3328, grad_fn=<AddBackward0>)\n",
      "tensor(2.3326, grad_fn=<AddBackward0>)\n",
      "tensor(2.3323, grad_fn=<AddBackward0>)\n",
      "tensor(2.3320, grad_fn=<AddBackward0>)\n",
      "tensor(2.3318, grad_fn=<AddBackward0>)\n",
      "tensor(2.3315, grad_fn=<AddBackward0>)\n",
      "tensor(2.3313, grad_fn=<AddBackward0>)\n",
      "tensor(2.3310, grad_fn=<AddBackward0>)\n",
      "tensor(2.3308, grad_fn=<AddBackward0>)\n",
      "tensor(2.3305, grad_fn=<AddBackward0>)\n",
      "tensor(2.3302, grad_fn=<AddBackward0>)\n",
      "tensor(2.3300, grad_fn=<AddBackward0>)\n",
      "tensor(2.3297, grad_fn=<AddBackward0>)\n",
      "tensor(2.3295, grad_fn=<AddBackward0>)\n",
      "tensor(2.3292, grad_fn=<AddBackward0>)\n",
      "tensor(2.3290, grad_fn=<AddBackward0>)\n",
      "tensor(2.3288, grad_fn=<AddBackward0>)\n",
      "tensor(2.3285, grad_fn=<AddBackward0>)\n",
      "tensor(2.3283, grad_fn=<AddBackward0>)\n",
      "tensor(2.3280, grad_fn=<AddBackward0>)\n",
      "tensor(2.3278, grad_fn=<AddBackward0>)\n",
      "tensor(2.3275, grad_fn=<AddBackward0>)\n",
      "tensor(2.3273, grad_fn=<AddBackward0>)\n",
      "tensor(2.3271, grad_fn=<AddBackward0>)\n",
      "tensor(2.3268, grad_fn=<AddBackward0>)\n",
      "tensor(2.3266, grad_fn=<AddBackward0>)\n",
      "tensor(2.3263, grad_fn=<AddBackward0>)\n",
      "tensor(2.3261, grad_fn=<AddBackward0>)\n",
      "tensor(2.3259, grad_fn=<AddBackward0>)\n",
      "tensor(2.3256, grad_fn=<AddBackward0>)\n",
      "tensor(2.3254, grad_fn=<AddBackward0>)\n",
      "tensor(2.3252, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "encoded = F.one_hot(torch.tensor(val_data), encoding_size).float()\n",
    "W = W\n",
    "\n",
    "for i in range(300):\n",
    "    logits = (encoded @ W)\n",
    "    counts = logits.exp()\n",
    "    probs = counts / counts.sum(1, keepdim=True)\n",
    "\n",
    "    loss = -probs[torch.arange(len(val_labels)), val_labels].log().mean() + 0.05 * (W**2).mean()\n",
    "\n",
    "    W.grad = None\n",
    "    loss.backward()\n",
    "    W.data += -W.grad * 50\n",
    "    print(loss)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E04: we saw that our 1-hot vectors merely select a row of W, so producing these vectors explicitly feels wasteful. Can you delete our use of F.one_hot in favor of simply indexing into rows of W?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "japtyn.\n",
      "kim.\n",
      "jameqhftans.\n",
      "naquin.\n",
      "aot.\n",
      "akyee.\n",
      "kadalebler.\n",
      "na.\n",
      "zanis.\n",
      "meibrey.\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    word = []\n",
    "    chars = \"..\"\n",
    "\n",
    "    while True:\n",
    "        current = chars[-2:]\n",
    "        datas = stoi_data.get(current, stoi_data[\"..\"])\n",
    "\n",
    "        logits = W[datas]\n",
    "        nums = logits.exp()\n",
    "        prob = nums / nums.sum(0, keepdim=True)\n",
    "        \n",
    "        idx = torch.multinomial(prob, num_samples=1, replacement=True).item()\n",
    "        word.append(itos_labels[idx])\n",
    "        chars += itos_labels[idx]\n",
    "        if chars[-1] == \".\":\n",
    "            break\n",
    "    print(\"\".join(word))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "look up and use F.cross_entropy instead. You should achieve the same result. Can you think of why we'd prefer to use F.cross_entropy instead?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.8124, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.6764, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.5861, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.5157, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.4549, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.4001, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.3499, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.3035, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2607, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2211, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1845, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1505, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1190, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0897, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0625, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0372, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0135, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.9913, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.9705, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.9510, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.9326, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.9152, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.8987, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.8831, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.8683, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.8542, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.8408, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.8280, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.8157, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.8040, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7928, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7821, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7717, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7618, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7523, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7431, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7342, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7257, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7175, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7095, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7018, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6944, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6872, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6802, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6735, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6669, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6605, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6543, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6483, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6424, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6367, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6311, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6257, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6204, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6153, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6103, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6054, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6006, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5959, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5913, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5868, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5825, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5782, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5740, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5699, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5659, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5619, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5581, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5543, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5506, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5470, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5434, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5399, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5365, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5332, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5299, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5266, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5235, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5203, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5173, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5143, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5113, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5084, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5056, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5028, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5000, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4973, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4946, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4920, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4894, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4869, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4844, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4820, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4795, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4772, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4748, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4725, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4702, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4680, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4658, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4636, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4615, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4594, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4573, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4553, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4533, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4513, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4493, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4474, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4455, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4436, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4417, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4399, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4381, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4363, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4346, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4328, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4311, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4294, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4278, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4261, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4245, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4229, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4213, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4198, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4182, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4167, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4152, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4137, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4122, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4108, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4093, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4079, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4065, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4051, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4037, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4024, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4011, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3997, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3984, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3971, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3958, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3946, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3933, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3921, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3909, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3896, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3884, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3872, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3861, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3849, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3838, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3826, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3815, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3804, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3793, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3782, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3771, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3760, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3750, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3739, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3729, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3718, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3708, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3698, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3688, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3678, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3668, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3658, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3649, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3639, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3630, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3620, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3611, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3602, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3593, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3584, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3575, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3566, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3557, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3548, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3540, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3531, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3522, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3514, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3506, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3497, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3489, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3481, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3473, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3465, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3457, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3449, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3441, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3433, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3426, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3418, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3410, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3403, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3395, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3388, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3381, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3373, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3366, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3359, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3352, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3345, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3338, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3331, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3324, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3317, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3310, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3303, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3297, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3290, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3283, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3277, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3270, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3264, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3257, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3251, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3245, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3238, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3232, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3226, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3220, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3214, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3208, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3202, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3196, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3190, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3184, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3178, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3172, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3166, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3161, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3155, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3149, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3144, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3138, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3133, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3127, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3122, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3116, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3111, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3105, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3100, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3095, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3089, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3084, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3079, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3074, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3069, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3064, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3059, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3053, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3048, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3044, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3039, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3034, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3029, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3024, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3019, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3014, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3010, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3005, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3000, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2995, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2991, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2986, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2982, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2977, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2972, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2968, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2963, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2959, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2955, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2950, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2946, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2941, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2937, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2933, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2929, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2924, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2920, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2916, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2912, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2907, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2903, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2899, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2895, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2891, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2887, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2883, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2879, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2875, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2871, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2867, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2863, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2859, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch\n",
    "encoding_size = len(stoi_data.keys())\n",
    "\n",
    "encoded = F.one_hot(torch.tensor(train_data), encoding_size).float()\n",
    "W = torch.randn((encoding_size, 27), requires_grad=True).float()\n",
    "\n",
    "for i in range(300):\n",
    "    logits = (encoded @ W)\n",
    "\n",
    "    loss = F.cross_entropy(logits, torch.tensor(train_labels))\n",
    "\n",
    "    W.grad = None\n",
    "    loss.backward()\n",
    "    W.data += -W.grad * 50\n",
    "    print(loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
