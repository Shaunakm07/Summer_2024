{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Import all dependancies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import exists\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.functional import log_softmax, pad\n",
    "import math\n",
    "import copy\n",
    "import time\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "from torchtext.data.functional import to_map_style_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "import torchtext.datasets as datasets\n",
    "import spacy\n",
    "import GPUtil\n",
    "import warnings\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Create the Model Architecture</h2>\n",
    "Encoder Maps the input sequence to a sequence of continuous representation and the decoder takes this and generates an output sequence one element at a time. We first build the general encoder decoder architecture before\n",
    "\n",
    "Sequence is passed into the encoder where embeddings are generated and then passed into the encoder class. A similar opperation happens with the decoder component but it all takes in the result of the encoder component as \"memory\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoder(nn.Module):\n",
    "    def __init__(self, encoder, decoder, src_embed, tgt_embed, generator):\n",
    "        super(EncoderDecoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.src_embed = src_embed\n",
    "        self.tgt_embed = tgt_embed\n",
    "        self.generator = generator\n",
    "\n",
    "    def forward(self, src, tgt, src_mask, tgt_mask):\n",
    "        encoded_result = self.encode(src, src_mask)\n",
    "        return self.decode(encoded_result, src_mask, tgt, tgt_mask)\n",
    "    \n",
    "    def encode(self, src, src_mask):\n",
    "        return self.encoder(self.src_embed(src), src_mask)\n",
    "    \n",
    "    def decode(self, memory, src_mask, tgt, tgt_mask):\n",
    "        return self.decoder(self.tgt_embed(tgt), memory, src_mask, tgt_mask)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Generator </h3>\n",
    "\n",
    "The generator is the standard linear + softmax part of the architecture. It is just a set of linear weights with a softmax opperation at the very end "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, d_model, vocab):\n",
    "        super(Generator, self).__init__()\n",
    "        self.proj = nn.Linear(d_model, vocab)\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.proj(x)\n",
    "        return log_softmax(logits, dim=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Â Encoder and Decoder Stacks </h3>\n",
    "\n",
    "The transformer follows an overall architecture using stacks of self attention for both the encoder and decoder. The encoder is composed of a stack of 6 identical Layers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clones(module, N):\n",
    "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, layer, N):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.layers = clones(layer, N)\n",
    "        self.norm = LayerNorm(layer.size)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, mask)\n",
    "        return self.norm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, features, eps=1e-6):\n",
    "        super(LayerNorm, self).__init__()\n",
    "        self.a_2 = nn.Parameter(torch.ones(features))\n",
    "        self.b_2 = nn.Parameter(torch.zeros(features))\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        std = x.std(-1, keepdim=True)\n",
    "        return self.a_2 * (x - mean) / (std + self.eps) + self.b_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SublayerConnection(nn.Module):\n",
    "    def __init__(self, size, dropout):\n",
    "        super(SublayerConnection, self).__init__()\n",
    "        self.norm = LayerNorm(size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, sublayer):\n",
    "        normalised = self.norm(x)\n",
    "        sublayer = sublayer(normalised)\n",
    "        dropout = self.dropout(sublayer)\n",
    "        residual = dropout + x\n",
    "        return residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder_Layer(nn.Module):\n",
    "    def __init__(self, size, self_attn, feed_forward, dropout):\n",
    "        super(Encoder_Layer, self).__init__()\n",
    "        self.self_attn = self_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.sublayer = clones(SublayerConnection(size, dropout), 2)\n",
    "        self.size = size\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        x = self.sublayer[0](x, lambda x:self.self_attn(x, x, x, mask))\n",
    "        return self.sublayer[1](x, self.feed_forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, layer, N):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.layers = clones(layer, N)\n",
    "        self.norm = LayerNorm(layer.size)\n",
    "\n",
    "    def forward(self, x, memory, src_mask, tgt_mask):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, memory, src_mask, tgt_mask)\n",
    "            return self.norm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, size, self_attn, src_attn, feed_forward, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.size = size\n",
    "        self.self_attn = self_attn\n",
    "        self.src_attn = src_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.sublayer = clones(SublayerConnection(size, dropout), 3)\n",
    "\n",
    "    def forward(self, x, memory, src_mask, tgt_mask):\n",
    "        m = memory\n",
    "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, tgt_mask))\n",
    "        x = self.sublayer[1](x, lambda x: self.src_attn(x, m, m, src_mask))\n",
    "        return self.sublayer[2](x, self.feed_forward)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Masking</h3>\n",
    "\n",
    "The input must be masked before sent to the attention layer as a word cannot look back to a word that comes after it. The triu function does this masking in pytorch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsequent_mask(size):\n",
    "    attn_shape = (1, size, size)\n",
    "    sub_mask = torch.triu(torch.ones(attn_shape), diagonal=1).type(torch.uint8)\n",
    "    return sub_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-561036e1c83b44dc80ea15a9ddabc61c.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-561036e1c83b44dc80ea15a9ddabc61c.vega-embed details,\n",
       "  #altair-viz-561036e1c83b44dc80ea15a9ddabc61c.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-561036e1c83b44dc80ea15a9ddabc61c\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-561036e1c83b44dc80ea15a9ddabc61c\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-561036e1c83b44dc80ea15a9ddabc61c\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-24f22f564c2395f116c5351f281b7bf0\"}, \"mark\": {\"type\": \"rect\"}, \"encoding\": {\"color\": {\"field\": \"Subsequent Mask\", \"scale\": {\"scheme\": \"viridis\"}, \"type\": \"quantitative\"}, \"x\": {\"field\": \"Window\", \"type\": \"ordinal\"}, \"y\": {\"field\": \"Masking\", \"type\": \"ordinal\"}}, \"height\": 250, \"params\": [{\"name\": \"param_1\", \"select\": {\"type\": \"interval\", \"encodings\": [\"x\", \"y\"]}, \"bind\": \"scales\"}], \"width\": 250, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.17.0.json\", \"datasets\": {\"data-24f22f564c2395f116c5351f281b7bf0\": [{\"Subsequent Mask\": 0, \"Window\": 0, \"Masking\": 0}, {\"Subsequent Mask\": 0, \"Window\": 0, \"Masking\": 1}, {\"Subsequent Mask\": 0, \"Window\": 0, \"Masking\": 2}, {\"Subsequent Mask\": 0, \"Window\": 0, \"Masking\": 3}, {\"Subsequent Mask\": 0, \"Window\": 0, \"Masking\": 4}, {\"Subsequent Mask\": 0, \"Window\": 0, \"Masking\": 5}, {\"Subsequent Mask\": 0, \"Window\": 0, \"Masking\": 6}, {\"Subsequent Mask\": 0, \"Window\": 0, \"Masking\": 7}, {\"Subsequent Mask\": 0, \"Window\": 0, \"Masking\": 8}, {\"Subsequent Mask\": 0, \"Window\": 0, \"Masking\": 9}, {\"Subsequent Mask\": 0, \"Window\": 0, \"Masking\": 10}, {\"Subsequent Mask\": 0, \"Window\": 0, \"Masking\": 11}, {\"Subsequent Mask\": 0, \"Window\": 0, \"Masking\": 12}, {\"Subsequent Mask\": 0, \"Window\": 0, \"Masking\": 13}, {\"Subsequent Mask\": 0, \"Window\": 0, \"Masking\": 14}, {\"Subsequent Mask\": 0, \"Window\": 0, \"Masking\": 15}, {\"Subsequent Mask\": 0, \"Window\": 0, \"Masking\": 16}, {\"Subsequent Mask\": 0, \"Window\": 0, \"Masking\": 17}, {\"Subsequent Mask\": 0, \"Window\": 0, \"Masking\": 18}, {\"Subsequent Mask\": 0, \"Window\": 0, \"Masking\": 19}, {\"Subsequent Mask\": 1, \"Window\": 1, \"Masking\": 0}, {\"Subsequent Mask\": 0, \"Window\": 1, \"Masking\": 1}, {\"Subsequent Mask\": 0, \"Window\": 1, \"Masking\": 2}, {\"Subsequent Mask\": 0, \"Window\": 1, \"Masking\": 3}, {\"Subsequent Mask\": 0, \"Window\": 1, \"Masking\": 4}, {\"Subsequent Mask\": 0, \"Window\": 1, \"Masking\": 5}, {\"Subsequent Mask\": 0, \"Window\": 1, \"Masking\": 6}, {\"Subsequent Mask\": 0, \"Window\": 1, \"Masking\": 7}, {\"Subsequent Mask\": 0, \"Window\": 1, \"Masking\": 8}, {\"Subsequent Mask\": 0, \"Window\": 1, \"Masking\": 9}, {\"Subsequent Mask\": 0, \"Window\": 1, \"Masking\": 10}, {\"Subsequent Mask\": 0, \"Window\": 1, \"Masking\": 11}, {\"Subsequent Mask\": 0, \"Window\": 1, \"Masking\": 12}, {\"Subsequent Mask\": 0, \"Window\": 1, \"Masking\": 13}, {\"Subsequent Mask\": 0, \"Window\": 1, \"Masking\": 14}, {\"Subsequent Mask\": 0, \"Window\": 1, \"Masking\": 15}, {\"Subsequent Mask\": 0, \"Window\": 1, \"Masking\": 16}, {\"Subsequent Mask\": 0, \"Window\": 1, \"Masking\": 17}, {\"Subsequent Mask\": 0, \"Window\": 1, \"Masking\": 18}, {\"Subsequent Mask\": 0, \"Window\": 1, \"Masking\": 19}, {\"Subsequent Mask\": 1, \"Window\": 2, \"Masking\": 0}, {\"Subsequent Mask\": 1, \"Window\": 2, \"Masking\": 1}, {\"Subsequent Mask\": 0, \"Window\": 2, \"Masking\": 2}, {\"Subsequent Mask\": 0, \"Window\": 2, \"Masking\": 3}, {\"Subsequent Mask\": 0, \"Window\": 2, \"Masking\": 4}, {\"Subsequent Mask\": 0, \"Window\": 2, \"Masking\": 5}, {\"Subsequent Mask\": 0, \"Window\": 2, \"Masking\": 6}, {\"Subsequent Mask\": 0, \"Window\": 2, \"Masking\": 7}, {\"Subsequent Mask\": 0, \"Window\": 2, \"Masking\": 8}, {\"Subsequent Mask\": 0, \"Window\": 2, \"Masking\": 9}, {\"Subsequent Mask\": 0, \"Window\": 2, \"Masking\": 10}, {\"Subsequent Mask\": 0, \"Window\": 2, \"Masking\": 11}, {\"Subsequent Mask\": 0, \"Window\": 2, \"Masking\": 12}, {\"Subsequent Mask\": 0, \"Window\": 2, \"Masking\": 13}, {\"Subsequent Mask\": 0, \"Window\": 2, \"Masking\": 14}, {\"Subsequent Mask\": 0, \"Window\": 2, \"Masking\": 15}, {\"Subsequent Mask\": 0, \"Window\": 2, \"Masking\": 16}, {\"Subsequent Mask\": 0, \"Window\": 2, \"Masking\": 17}, {\"Subsequent Mask\": 0, \"Window\": 2, \"Masking\": 18}, {\"Subsequent Mask\": 0, \"Window\": 2, \"Masking\": 19}, {\"Subsequent Mask\": 1, \"Window\": 3, \"Masking\": 0}, {\"Subsequent Mask\": 1, \"Window\": 3, \"Masking\": 1}, {\"Subsequent Mask\": 1, \"Window\": 3, \"Masking\": 2}, {\"Subsequent Mask\": 0, \"Window\": 3, \"Masking\": 3}, {\"Subsequent Mask\": 0, \"Window\": 3, \"Masking\": 4}, {\"Subsequent Mask\": 0, \"Window\": 3, \"Masking\": 5}, {\"Subsequent Mask\": 0, \"Window\": 3, \"Masking\": 6}, {\"Subsequent Mask\": 0, \"Window\": 3, \"Masking\": 7}, {\"Subsequent Mask\": 0, \"Window\": 3, \"Masking\": 8}, {\"Subsequent Mask\": 0, \"Window\": 3, \"Masking\": 9}, {\"Subsequent Mask\": 0, \"Window\": 3, \"Masking\": 10}, {\"Subsequent Mask\": 0, \"Window\": 3, \"Masking\": 11}, {\"Subsequent Mask\": 0, \"Window\": 3, \"Masking\": 12}, {\"Subsequent Mask\": 0, \"Window\": 3, \"Masking\": 13}, {\"Subsequent Mask\": 0, \"Window\": 3, \"Masking\": 14}, {\"Subsequent Mask\": 0, \"Window\": 3, \"Masking\": 15}, {\"Subsequent Mask\": 0, \"Window\": 3, \"Masking\": 16}, {\"Subsequent Mask\": 0, \"Window\": 3, \"Masking\": 17}, {\"Subsequent Mask\": 0, \"Window\": 3, \"Masking\": 18}, {\"Subsequent Mask\": 0, \"Window\": 3, \"Masking\": 19}, {\"Subsequent Mask\": 1, \"Window\": 4, \"Masking\": 0}, {\"Subsequent Mask\": 1, \"Window\": 4, \"Masking\": 1}, {\"Subsequent Mask\": 1, \"Window\": 4, \"Masking\": 2}, {\"Subsequent Mask\": 1, \"Window\": 4, \"Masking\": 3}, {\"Subsequent Mask\": 0, \"Window\": 4, \"Masking\": 4}, {\"Subsequent Mask\": 0, \"Window\": 4, \"Masking\": 5}, {\"Subsequent Mask\": 0, \"Window\": 4, \"Masking\": 6}, {\"Subsequent Mask\": 0, \"Window\": 4, \"Masking\": 7}, {\"Subsequent Mask\": 0, \"Window\": 4, \"Masking\": 8}, {\"Subsequent Mask\": 0, \"Window\": 4, \"Masking\": 9}, {\"Subsequent Mask\": 0, \"Window\": 4, \"Masking\": 10}, {\"Subsequent Mask\": 0, \"Window\": 4, \"Masking\": 11}, {\"Subsequent Mask\": 0, \"Window\": 4, \"Masking\": 12}, {\"Subsequent Mask\": 0, \"Window\": 4, \"Masking\": 13}, {\"Subsequent Mask\": 0, \"Window\": 4, \"Masking\": 14}, {\"Subsequent Mask\": 0, \"Window\": 4, \"Masking\": 15}, {\"Subsequent Mask\": 0, \"Window\": 4, \"Masking\": 16}, {\"Subsequent Mask\": 0, \"Window\": 4, \"Masking\": 17}, {\"Subsequent Mask\": 0, \"Window\": 4, \"Masking\": 18}, {\"Subsequent Mask\": 0, \"Window\": 4, \"Masking\": 19}, {\"Subsequent Mask\": 1, \"Window\": 5, \"Masking\": 0}, {\"Subsequent Mask\": 1, \"Window\": 5, \"Masking\": 1}, {\"Subsequent Mask\": 1, \"Window\": 5, \"Masking\": 2}, {\"Subsequent Mask\": 1, \"Window\": 5, \"Masking\": 3}, {\"Subsequent Mask\": 1, \"Window\": 5, \"Masking\": 4}, {\"Subsequent Mask\": 0, \"Window\": 5, \"Masking\": 5}, {\"Subsequent Mask\": 0, \"Window\": 5, \"Masking\": 6}, {\"Subsequent Mask\": 0, \"Window\": 5, \"Masking\": 7}, {\"Subsequent Mask\": 0, \"Window\": 5, \"Masking\": 8}, {\"Subsequent Mask\": 0, \"Window\": 5, \"Masking\": 9}, {\"Subsequent Mask\": 0, \"Window\": 5, \"Masking\": 10}, {\"Subsequent Mask\": 0, \"Window\": 5, \"Masking\": 11}, {\"Subsequent Mask\": 0, \"Window\": 5, \"Masking\": 12}, {\"Subsequent Mask\": 0, \"Window\": 5, \"Masking\": 13}, {\"Subsequent Mask\": 0, \"Window\": 5, \"Masking\": 14}, {\"Subsequent Mask\": 0, \"Window\": 5, \"Masking\": 15}, {\"Subsequent Mask\": 0, \"Window\": 5, \"Masking\": 16}, {\"Subsequent Mask\": 0, \"Window\": 5, \"Masking\": 17}, {\"Subsequent Mask\": 0, \"Window\": 5, \"Masking\": 18}, {\"Subsequent Mask\": 0, \"Window\": 5, \"Masking\": 19}, {\"Subsequent Mask\": 1, \"Window\": 6, \"Masking\": 0}, {\"Subsequent Mask\": 1, \"Window\": 6, \"Masking\": 1}, {\"Subsequent Mask\": 1, \"Window\": 6, \"Masking\": 2}, {\"Subsequent Mask\": 1, \"Window\": 6, \"Masking\": 3}, {\"Subsequent Mask\": 1, \"Window\": 6, \"Masking\": 4}, {\"Subsequent Mask\": 1, \"Window\": 6, \"Masking\": 5}, {\"Subsequent Mask\": 0, \"Window\": 6, \"Masking\": 6}, {\"Subsequent Mask\": 0, \"Window\": 6, \"Masking\": 7}, {\"Subsequent Mask\": 0, \"Window\": 6, \"Masking\": 8}, {\"Subsequent Mask\": 0, \"Window\": 6, \"Masking\": 9}, {\"Subsequent Mask\": 0, \"Window\": 6, \"Masking\": 10}, {\"Subsequent Mask\": 0, \"Window\": 6, \"Masking\": 11}, {\"Subsequent Mask\": 0, \"Window\": 6, \"Masking\": 12}, {\"Subsequent Mask\": 0, \"Window\": 6, \"Masking\": 13}, {\"Subsequent Mask\": 0, \"Window\": 6, \"Masking\": 14}, {\"Subsequent Mask\": 0, \"Window\": 6, \"Masking\": 15}, {\"Subsequent Mask\": 0, \"Window\": 6, \"Masking\": 16}, {\"Subsequent Mask\": 0, \"Window\": 6, \"Masking\": 17}, {\"Subsequent Mask\": 0, \"Window\": 6, \"Masking\": 18}, {\"Subsequent Mask\": 0, \"Window\": 6, \"Masking\": 19}, {\"Subsequent Mask\": 1, \"Window\": 7, \"Masking\": 0}, {\"Subsequent Mask\": 1, \"Window\": 7, \"Masking\": 1}, {\"Subsequent Mask\": 1, \"Window\": 7, \"Masking\": 2}, {\"Subsequent Mask\": 1, \"Window\": 7, \"Masking\": 3}, {\"Subsequent Mask\": 1, \"Window\": 7, \"Masking\": 4}, {\"Subsequent Mask\": 1, \"Window\": 7, \"Masking\": 5}, {\"Subsequent Mask\": 1, \"Window\": 7, \"Masking\": 6}, {\"Subsequent Mask\": 0, \"Window\": 7, \"Masking\": 7}, {\"Subsequent Mask\": 0, \"Window\": 7, \"Masking\": 8}, {\"Subsequent Mask\": 0, \"Window\": 7, \"Masking\": 9}, {\"Subsequent Mask\": 0, \"Window\": 7, \"Masking\": 10}, {\"Subsequent Mask\": 0, \"Window\": 7, \"Masking\": 11}, {\"Subsequent Mask\": 0, \"Window\": 7, \"Masking\": 12}, {\"Subsequent Mask\": 0, \"Window\": 7, \"Masking\": 13}, {\"Subsequent Mask\": 0, \"Window\": 7, \"Masking\": 14}, {\"Subsequent Mask\": 0, \"Window\": 7, \"Masking\": 15}, {\"Subsequent Mask\": 0, \"Window\": 7, \"Masking\": 16}, {\"Subsequent Mask\": 0, \"Window\": 7, \"Masking\": 17}, {\"Subsequent Mask\": 0, \"Window\": 7, \"Masking\": 18}, {\"Subsequent Mask\": 0, \"Window\": 7, \"Masking\": 19}, {\"Subsequent Mask\": 1, \"Window\": 8, \"Masking\": 0}, {\"Subsequent Mask\": 1, \"Window\": 8, \"Masking\": 1}, {\"Subsequent Mask\": 1, \"Window\": 8, \"Masking\": 2}, {\"Subsequent Mask\": 1, \"Window\": 8, \"Masking\": 3}, {\"Subsequent Mask\": 1, \"Window\": 8, \"Masking\": 4}, {\"Subsequent Mask\": 1, \"Window\": 8, \"Masking\": 5}, {\"Subsequent Mask\": 1, \"Window\": 8, \"Masking\": 6}, {\"Subsequent Mask\": 1, \"Window\": 8, \"Masking\": 7}, {\"Subsequent Mask\": 0, \"Window\": 8, \"Masking\": 8}, {\"Subsequent Mask\": 0, \"Window\": 8, \"Masking\": 9}, {\"Subsequent Mask\": 0, \"Window\": 8, \"Masking\": 10}, {\"Subsequent Mask\": 0, \"Window\": 8, \"Masking\": 11}, {\"Subsequent Mask\": 0, \"Window\": 8, \"Masking\": 12}, {\"Subsequent Mask\": 0, \"Window\": 8, \"Masking\": 13}, {\"Subsequent Mask\": 0, \"Window\": 8, \"Masking\": 14}, {\"Subsequent Mask\": 0, \"Window\": 8, \"Masking\": 15}, {\"Subsequent Mask\": 0, \"Window\": 8, \"Masking\": 16}, {\"Subsequent Mask\": 0, \"Window\": 8, \"Masking\": 17}, {\"Subsequent Mask\": 0, \"Window\": 8, \"Masking\": 18}, {\"Subsequent Mask\": 0, \"Window\": 8, \"Masking\": 19}, {\"Subsequent Mask\": 1, \"Window\": 9, \"Masking\": 0}, {\"Subsequent Mask\": 1, \"Window\": 9, \"Masking\": 1}, {\"Subsequent Mask\": 1, \"Window\": 9, \"Masking\": 2}, {\"Subsequent Mask\": 1, \"Window\": 9, \"Masking\": 3}, {\"Subsequent Mask\": 1, \"Window\": 9, \"Masking\": 4}, {\"Subsequent Mask\": 1, \"Window\": 9, \"Masking\": 5}, {\"Subsequent Mask\": 1, \"Window\": 9, \"Masking\": 6}, {\"Subsequent Mask\": 1, \"Window\": 9, \"Masking\": 7}, {\"Subsequent Mask\": 1, \"Window\": 9, \"Masking\": 8}, {\"Subsequent Mask\": 0, \"Window\": 9, \"Masking\": 9}, {\"Subsequent Mask\": 0, \"Window\": 9, \"Masking\": 10}, {\"Subsequent Mask\": 0, \"Window\": 9, \"Masking\": 11}, {\"Subsequent Mask\": 0, \"Window\": 9, \"Masking\": 12}, {\"Subsequent Mask\": 0, \"Window\": 9, \"Masking\": 13}, {\"Subsequent Mask\": 0, \"Window\": 9, \"Masking\": 14}, {\"Subsequent Mask\": 0, \"Window\": 9, \"Masking\": 15}, {\"Subsequent Mask\": 0, \"Window\": 9, \"Masking\": 16}, {\"Subsequent Mask\": 0, \"Window\": 9, \"Masking\": 17}, {\"Subsequent Mask\": 0, \"Window\": 9, \"Masking\": 18}, {\"Subsequent Mask\": 0, \"Window\": 9, \"Masking\": 19}, {\"Subsequent Mask\": 1, \"Window\": 10, \"Masking\": 0}, {\"Subsequent Mask\": 1, \"Window\": 10, \"Masking\": 1}, {\"Subsequent Mask\": 1, \"Window\": 10, \"Masking\": 2}, {\"Subsequent Mask\": 1, \"Window\": 10, \"Masking\": 3}, {\"Subsequent Mask\": 1, \"Window\": 10, \"Masking\": 4}, {\"Subsequent Mask\": 1, \"Window\": 10, \"Masking\": 5}, {\"Subsequent Mask\": 1, \"Window\": 10, \"Masking\": 6}, {\"Subsequent Mask\": 1, \"Window\": 10, \"Masking\": 7}, {\"Subsequent Mask\": 1, \"Window\": 10, \"Masking\": 8}, {\"Subsequent Mask\": 1, \"Window\": 10, \"Masking\": 9}, {\"Subsequent Mask\": 0, \"Window\": 10, \"Masking\": 10}, {\"Subsequent Mask\": 0, \"Window\": 10, \"Masking\": 11}, {\"Subsequent Mask\": 0, \"Window\": 10, \"Masking\": 12}, {\"Subsequent Mask\": 0, \"Window\": 10, \"Masking\": 13}, {\"Subsequent Mask\": 0, \"Window\": 10, \"Masking\": 14}, {\"Subsequent Mask\": 0, \"Window\": 10, \"Masking\": 15}, {\"Subsequent Mask\": 0, \"Window\": 10, \"Masking\": 16}, {\"Subsequent Mask\": 0, \"Window\": 10, \"Masking\": 17}, {\"Subsequent Mask\": 0, \"Window\": 10, \"Masking\": 18}, {\"Subsequent Mask\": 0, \"Window\": 10, \"Masking\": 19}, {\"Subsequent Mask\": 1, \"Window\": 11, \"Masking\": 0}, {\"Subsequent Mask\": 1, \"Window\": 11, \"Masking\": 1}, {\"Subsequent Mask\": 1, \"Window\": 11, \"Masking\": 2}, {\"Subsequent Mask\": 1, \"Window\": 11, \"Masking\": 3}, {\"Subsequent Mask\": 1, \"Window\": 11, \"Masking\": 4}, {\"Subsequent Mask\": 1, \"Window\": 11, \"Masking\": 5}, {\"Subsequent Mask\": 1, \"Window\": 11, \"Masking\": 6}, {\"Subsequent Mask\": 1, \"Window\": 11, \"Masking\": 7}, {\"Subsequent Mask\": 1, \"Window\": 11, \"Masking\": 8}, {\"Subsequent Mask\": 1, \"Window\": 11, \"Masking\": 9}, {\"Subsequent Mask\": 1, \"Window\": 11, \"Masking\": 10}, {\"Subsequent Mask\": 0, \"Window\": 11, \"Masking\": 11}, {\"Subsequent Mask\": 0, \"Window\": 11, \"Masking\": 12}, {\"Subsequent Mask\": 0, \"Window\": 11, \"Masking\": 13}, {\"Subsequent Mask\": 0, \"Window\": 11, \"Masking\": 14}, {\"Subsequent Mask\": 0, \"Window\": 11, \"Masking\": 15}, {\"Subsequent Mask\": 0, \"Window\": 11, \"Masking\": 16}, {\"Subsequent Mask\": 0, \"Window\": 11, \"Masking\": 17}, {\"Subsequent Mask\": 0, \"Window\": 11, \"Masking\": 18}, {\"Subsequent Mask\": 0, \"Window\": 11, \"Masking\": 19}, {\"Subsequent Mask\": 1, \"Window\": 12, \"Masking\": 0}, {\"Subsequent Mask\": 1, \"Window\": 12, \"Masking\": 1}, {\"Subsequent Mask\": 1, \"Window\": 12, \"Masking\": 2}, {\"Subsequent Mask\": 1, \"Window\": 12, \"Masking\": 3}, {\"Subsequent Mask\": 1, \"Window\": 12, \"Masking\": 4}, {\"Subsequent Mask\": 1, \"Window\": 12, \"Masking\": 5}, {\"Subsequent Mask\": 1, \"Window\": 12, \"Masking\": 6}, {\"Subsequent Mask\": 1, \"Window\": 12, \"Masking\": 7}, {\"Subsequent Mask\": 1, \"Window\": 12, \"Masking\": 8}, {\"Subsequent Mask\": 1, \"Window\": 12, \"Masking\": 9}, {\"Subsequent Mask\": 1, \"Window\": 12, \"Masking\": 10}, {\"Subsequent Mask\": 1, \"Window\": 12, \"Masking\": 11}, {\"Subsequent Mask\": 0, \"Window\": 12, \"Masking\": 12}, {\"Subsequent Mask\": 0, \"Window\": 12, \"Masking\": 13}, {\"Subsequent Mask\": 0, \"Window\": 12, \"Masking\": 14}, {\"Subsequent Mask\": 0, \"Window\": 12, \"Masking\": 15}, {\"Subsequent Mask\": 0, \"Window\": 12, \"Masking\": 16}, {\"Subsequent Mask\": 0, \"Window\": 12, \"Masking\": 17}, {\"Subsequent Mask\": 0, \"Window\": 12, \"Masking\": 18}, {\"Subsequent Mask\": 0, \"Window\": 12, \"Masking\": 19}, {\"Subsequent Mask\": 1, \"Window\": 13, \"Masking\": 0}, {\"Subsequent Mask\": 1, \"Window\": 13, \"Masking\": 1}, {\"Subsequent Mask\": 1, \"Window\": 13, \"Masking\": 2}, {\"Subsequent Mask\": 1, \"Window\": 13, \"Masking\": 3}, {\"Subsequent Mask\": 1, \"Window\": 13, \"Masking\": 4}, {\"Subsequent Mask\": 1, \"Window\": 13, \"Masking\": 5}, {\"Subsequent Mask\": 1, \"Window\": 13, \"Masking\": 6}, {\"Subsequent Mask\": 1, \"Window\": 13, \"Masking\": 7}, {\"Subsequent Mask\": 1, \"Window\": 13, \"Masking\": 8}, {\"Subsequent Mask\": 1, \"Window\": 13, \"Masking\": 9}, {\"Subsequent Mask\": 1, \"Window\": 13, \"Masking\": 10}, {\"Subsequent Mask\": 1, \"Window\": 13, \"Masking\": 11}, {\"Subsequent Mask\": 1, \"Window\": 13, \"Masking\": 12}, {\"Subsequent Mask\": 0, \"Window\": 13, \"Masking\": 13}, {\"Subsequent Mask\": 0, \"Window\": 13, \"Masking\": 14}, {\"Subsequent Mask\": 0, \"Window\": 13, \"Masking\": 15}, {\"Subsequent Mask\": 0, \"Window\": 13, \"Masking\": 16}, {\"Subsequent Mask\": 0, \"Window\": 13, \"Masking\": 17}, {\"Subsequent Mask\": 0, \"Window\": 13, \"Masking\": 18}, {\"Subsequent Mask\": 0, \"Window\": 13, \"Masking\": 19}, {\"Subsequent Mask\": 1, \"Window\": 14, \"Masking\": 0}, {\"Subsequent Mask\": 1, \"Window\": 14, \"Masking\": 1}, {\"Subsequent Mask\": 1, \"Window\": 14, \"Masking\": 2}, {\"Subsequent Mask\": 1, \"Window\": 14, \"Masking\": 3}, {\"Subsequent Mask\": 1, \"Window\": 14, \"Masking\": 4}, {\"Subsequent Mask\": 1, \"Window\": 14, \"Masking\": 5}, {\"Subsequent Mask\": 1, \"Window\": 14, \"Masking\": 6}, {\"Subsequent Mask\": 1, \"Window\": 14, \"Masking\": 7}, {\"Subsequent Mask\": 1, \"Window\": 14, \"Masking\": 8}, {\"Subsequent Mask\": 1, \"Window\": 14, \"Masking\": 9}, {\"Subsequent Mask\": 1, \"Window\": 14, \"Masking\": 10}, {\"Subsequent Mask\": 1, \"Window\": 14, \"Masking\": 11}, {\"Subsequent Mask\": 1, \"Window\": 14, \"Masking\": 12}, {\"Subsequent Mask\": 1, \"Window\": 14, \"Masking\": 13}, {\"Subsequent Mask\": 0, \"Window\": 14, \"Masking\": 14}, {\"Subsequent Mask\": 0, \"Window\": 14, \"Masking\": 15}, {\"Subsequent Mask\": 0, \"Window\": 14, \"Masking\": 16}, {\"Subsequent Mask\": 0, \"Window\": 14, \"Masking\": 17}, {\"Subsequent Mask\": 0, \"Window\": 14, \"Masking\": 18}, {\"Subsequent Mask\": 0, \"Window\": 14, \"Masking\": 19}, {\"Subsequent Mask\": 1, \"Window\": 15, \"Masking\": 0}, {\"Subsequent Mask\": 1, \"Window\": 15, \"Masking\": 1}, {\"Subsequent Mask\": 1, \"Window\": 15, \"Masking\": 2}, {\"Subsequent Mask\": 1, \"Window\": 15, \"Masking\": 3}, {\"Subsequent Mask\": 1, \"Window\": 15, \"Masking\": 4}, {\"Subsequent Mask\": 1, \"Window\": 15, \"Masking\": 5}, {\"Subsequent Mask\": 1, \"Window\": 15, \"Masking\": 6}, {\"Subsequent Mask\": 1, \"Window\": 15, \"Masking\": 7}, {\"Subsequent Mask\": 1, \"Window\": 15, \"Masking\": 8}, {\"Subsequent Mask\": 1, \"Window\": 15, \"Masking\": 9}, {\"Subsequent Mask\": 1, \"Window\": 15, \"Masking\": 10}, {\"Subsequent Mask\": 1, \"Window\": 15, \"Masking\": 11}, {\"Subsequent Mask\": 1, \"Window\": 15, \"Masking\": 12}, {\"Subsequent Mask\": 1, \"Window\": 15, \"Masking\": 13}, {\"Subsequent Mask\": 1, \"Window\": 15, \"Masking\": 14}, {\"Subsequent Mask\": 0, \"Window\": 15, \"Masking\": 15}, {\"Subsequent Mask\": 0, \"Window\": 15, \"Masking\": 16}, {\"Subsequent Mask\": 0, \"Window\": 15, \"Masking\": 17}, {\"Subsequent Mask\": 0, \"Window\": 15, \"Masking\": 18}, {\"Subsequent Mask\": 0, \"Window\": 15, \"Masking\": 19}, {\"Subsequent Mask\": 1, \"Window\": 16, \"Masking\": 0}, {\"Subsequent Mask\": 1, \"Window\": 16, \"Masking\": 1}, {\"Subsequent Mask\": 1, \"Window\": 16, \"Masking\": 2}, {\"Subsequent Mask\": 1, \"Window\": 16, \"Masking\": 3}, {\"Subsequent Mask\": 1, \"Window\": 16, \"Masking\": 4}, {\"Subsequent Mask\": 1, \"Window\": 16, \"Masking\": 5}, {\"Subsequent Mask\": 1, \"Window\": 16, \"Masking\": 6}, {\"Subsequent Mask\": 1, \"Window\": 16, \"Masking\": 7}, {\"Subsequent Mask\": 1, \"Window\": 16, \"Masking\": 8}, {\"Subsequent Mask\": 1, \"Window\": 16, \"Masking\": 9}, {\"Subsequent Mask\": 1, \"Window\": 16, \"Masking\": 10}, {\"Subsequent Mask\": 1, \"Window\": 16, \"Masking\": 11}, {\"Subsequent Mask\": 1, \"Window\": 16, \"Masking\": 12}, {\"Subsequent Mask\": 1, \"Window\": 16, \"Masking\": 13}, {\"Subsequent Mask\": 1, \"Window\": 16, \"Masking\": 14}, {\"Subsequent Mask\": 1, \"Window\": 16, \"Masking\": 15}, {\"Subsequent Mask\": 0, \"Window\": 16, \"Masking\": 16}, {\"Subsequent Mask\": 0, \"Window\": 16, \"Masking\": 17}, {\"Subsequent Mask\": 0, \"Window\": 16, \"Masking\": 18}, {\"Subsequent Mask\": 0, \"Window\": 16, \"Masking\": 19}, {\"Subsequent Mask\": 1, \"Window\": 17, \"Masking\": 0}, {\"Subsequent Mask\": 1, \"Window\": 17, \"Masking\": 1}, {\"Subsequent Mask\": 1, \"Window\": 17, \"Masking\": 2}, {\"Subsequent Mask\": 1, \"Window\": 17, \"Masking\": 3}, {\"Subsequent Mask\": 1, \"Window\": 17, \"Masking\": 4}, {\"Subsequent Mask\": 1, \"Window\": 17, \"Masking\": 5}, {\"Subsequent Mask\": 1, \"Window\": 17, \"Masking\": 6}, {\"Subsequent Mask\": 1, \"Window\": 17, \"Masking\": 7}, {\"Subsequent Mask\": 1, \"Window\": 17, \"Masking\": 8}, {\"Subsequent Mask\": 1, \"Window\": 17, \"Masking\": 9}, {\"Subsequent Mask\": 1, \"Window\": 17, \"Masking\": 10}, {\"Subsequent Mask\": 1, \"Window\": 17, \"Masking\": 11}, {\"Subsequent Mask\": 1, \"Window\": 17, \"Masking\": 12}, {\"Subsequent Mask\": 1, \"Window\": 17, \"Masking\": 13}, {\"Subsequent Mask\": 1, \"Window\": 17, \"Masking\": 14}, {\"Subsequent Mask\": 1, \"Window\": 17, \"Masking\": 15}, {\"Subsequent Mask\": 1, \"Window\": 17, \"Masking\": 16}, {\"Subsequent Mask\": 0, \"Window\": 17, \"Masking\": 17}, {\"Subsequent Mask\": 0, \"Window\": 17, \"Masking\": 18}, {\"Subsequent Mask\": 0, \"Window\": 17, \"Masking\": 19}, {\"Subsequent Mask\": 1, \"Window\": 18, \"Masking\": 0}, {\"Subsequent Mask\": 1, \"Window\": 18, \"Masking\": 1}, {\"Subsequent Mask\": 1, \"Window\": 18, \"Masking\": 2}, {\"Subsequent Mask\": 1, \"Window\": 18, \"Masking\": 3}, {\"Subsequent Mask\": 1, \"Window\": 18, \"Masking\": 4}, {\"Subsequent Mask\": 1, \"Window\": 18, \"Masking\": 5}, {\"Subsequent Mask\": 1, \"Window\": 18, \"Masking\": 6}, {\"Subsequent Mask\": 1, \"Window\": 18, \"Masking\": 7}, {\"Subsequent Mask\": 1, \"Window\": 18, \"Masking\": 8}, {\"Subsequent Mask\": 1, \"Window\": 18, \"Masking\": 9}, {\"Subsequent Mask\": 1, \"Window\": 18, \"Masking\": 10}, {\"Subsequent Mask\": 1, \"Window\": 18, \"Masking\": 11}, {\"Subsequent Mask\": 1, \"Window\": 18, \"Masking\": 12}, {\"Subsequent Mask\": 1, \"Window\": 18, \"Masking\": 13}, {\"Subsequent Mask\": 1, \"Window\": 18, \"Masking\": 14}, {\"Subsequent Mask\": 1, \"Window\": 18, \"Masking\": 15}, {\"Subsequent Mask\": 1, \"Window\": 18, \"Masking\": 16}, {\"Subsequent Mask\": 1, \"Window\": 18, \"Masking\": 17}, {\"Subsequent Mask\": 0, \"Window\": 18, \"Masking\": 18}, {\"Subsequent Mask\": 0, \"Window\": 18, \"Masking\": 19}, {\"Subsequent Mask\": 1, \"Window\": 19, \"Masking\": 0}, {\"Subsequent Mask\": 1, \"Window\": 19, \"Masking\": 1}, {\"Subsequent Mask\": 1, \"Window\": 19, \"Masking\": 2}, {\"Subsequent Mask\": 1, \"Window\": 19, \"Masking\": 3}, {\"Subsequent Mask\": 1, \"Window\": 19, \"Masking\": 4}, {\"Subsequent Mask\": 1, \"Window\": 19, \"Masking\": 5}, {\"Subsequent Mask\": 1, \"Window\": 19, \"Masking\": 6}, {\"Subsequent Mask\": 1, \"Window\": 19, \"Masking\": 7}, {\"Subsequent Mask\": 1, \"Window\": 19, \"Masking\": 8}, {\"Subsequent Mask\": 1, \"Window\": 19, \"Masking\": 9}, {\"Subsequent Mask\": 1, \"Window\": 19, \"Masking\": 10}, {\"Subsequent Mask\": 1, \"Window\": 19, \"Masking\": 11}, {\"Subsequent Mask\": 1, \"Window\": 19, \"Masking\": 12}, {\"Subsequent Mask\": 1, \"Window\": 19, \"Masking\": 13}, {\"Subsequent Mask\": 1, \"Window\": 19, \"Masking\": 14}, {\"Subsequent Mask\": 1, \"Window\": 19, \"Masking\": 15}, {\"Subsequent Mask\": 1, \"Window\": 19, \"Masking\": 16}, {\"Subsequent Mask\": 1, \"Window\": 19, \"Masking\": 17}, {\"Subsequent Mask\": 1, \"Window\": 19, \"Masking\": 18}, {\"Subsequent Mask\": 0, \"Window\": 19, \"Masking\": 19}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def example_mask():\n",
    "    LS_data = pd.concat(\n",
    "        [\n",
    "            pd.DataFrame(\n",
    "                {\n",
    "                    \"Subsequent Mask\": subsequent_mask(20)[0][x, y].flatten(),\n",
    "                    \"Window\": y,\n",
    "                    \"Masking\": x,\n",
    "                }\n",
    "            )\n",
    "            for y in range(20)\n",
    "            for x in range(20)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        alt.Chart(LS_data)\n",
    "        .mark_rect()\n",
    "        .properties(height=250, width=250)\n",
    "        .encode(\n",
    "            alt.X(\"Window:O\"),\n",
    "            alt.Y(\"Masking:O\"),\n",
    "            alt.Color(\"Subsequent Mask:Q\", scale=alt.Scale(scheme=\"viridis\")),\n",
    "        )\n",
    "        .interactive()\n",
    "    )\n",
    "\n",
    "\n",
    "example_mask()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Attention!</h3>\n",
    "\n",
    "We first compute self attention before combining 8 self attention heads to form multi head attention "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention(query, key, value, mask=None, dropout=None):\n",
    "    d_k = query.size[-1]\n",
    "    scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        scores = scores.masked_fill(mask == 0, -1e9)\n",
    "    p_attn = scores.softmax(dim=-1)\n",
    "    if dropout is not None:\n",
    "        p_attn = dropout(p_attn)\n",
    "    return torch.matmul(p_attn, value), p_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadedAttention(nn.Module):\n",
    "    def __init__(self, h, d_model, dropout=0.1):\n",
    "        super(MultiHeadedAttention, self).__init__()\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
